{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"word2vec_gensim.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"lx6IqlFNNpAg","executionInfo":{"status":"ok","timestamp":1618775050536,"user_tz":-120,"elapsed":719,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["#from IPython.core.display import display, HTML\n","#display(HTML(\"<style>.container { width:80% !important; }</style>\"))"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOIt1k_CmnEN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618775067065,"user_tz":-120,"elapsed":17239,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"c8149839-6f0d-4960-9c87-fbdf10fc27ee"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EJyA4NvLNuhy","executionInfo":{"status":"ok","timestamp":1618775369755,"user_tz":-120,"elapsed":319922,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["%%capture\n","!pip install xlrd=='1.1.0' gensim=='3.4.0' scikit-learn=='0.19.1' seaborn=='0.8' spaCy=='2.0.12'"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"84163f3ca19c0b7c9fda47121b3bc4cadfaf1fcc","id":"jCE2FZkuNpAp"},"source":["# <font color=#003091> Introducción resultados Word2Vec - Simpsons </font>\n","\n","- Autor original del kernel: https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial"]},{"cell_type":"markdown","metadata":{"_uuid":"6721f3a77cbc903d996b88c42f22c3e5e920e909","id":"ek9SzlqwNpAq"},"source":["\n","<img src=\"https://images.freeimages.com/images/large-previews/2b9/letters-1-yes-1188348.jpg\" alt=\"drawing\" width=\"350\"/>"]},{"cell_type":"markdown","metadata":{"_uuid":"7d96105f0c90bf052b2afdb684bf31549e1e6c81","id":"FDKwbu3NNpAq"},"source":["# Briefing about Word2Vec:\n","\n","<img src=\"http://mccormickml.com/assets/word2vec/skip_gram_net_arch.png\" alt=\"drawing\" width=\"950\"/>\n","\n","[[1]](#References:)\n","\n","\n"]},{"cell_type":"code","metadata":{"_uuid":"cc7b3e6ca62670ff13626705402f626778487204","id":"5w0EtrNwNpAr","executionInfo":{"status":"ok","timestamp":1618775370581,"user_tz":-120,"elapsed":320742,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["import re  # For preprocessing\n","import pandas as pd  # For data handling\n","from time import time  # To time our operations\n","from collections import defaultdict  # For word frequency\n","\n","import spacy  # For preprocessing\n","\n","import logging  # Setting up the loggings to monitor gensim\n","logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"8ec7ce784f6d9e7f71e2b5789b1e65ec4414628b","id":"qSa0xBlhNpAr"},"source":["<img src=\"https://upload.wikimedia.org/wikipedia/commons/4/44/Logo_The_Simpsons.svg\" alt=\"drawing\" width=\"400\"/>\n","\n","## Los datos:\n","Se eligió un script de los Simpson, porque tienen más de 150k lineas de diálogos y porque los Simpson es conocido\n","\n","El dataset contiene los caracteres, localizaciones, detalles de episodios, y lineas de diálogos de aproximadamente 600 episodios de los Simpsons, desde 1989. El conjunto de datos se puede encontrar aquí:\n","https://www.kaggle.com/ambarish/fun-in-text-mining-with-simpsons/data (~25MB)"]},{"cell_type":"markdown","metadata":{"_uuid":"0c36323d9aa62f74ab348cda5ee0f571aa1d4a96","id":"A5VlVAADNpAr"},"source":["# Preprocessing\n","\n","Nos quedamos solo con dos columnas:\n","* `raw_character_text`: la persona que habla\n","* `spoken_words`: Su diálogo\n","\n","No se utiliza la columna `normalized_text` porque deseamos hacer nuestro propio pre-procesado."]},{"cell_type":"code","metadata":{"_uuid":"6453b9c3f797e51923e030090ead659253f4e459","id":"K6qHb6RcNpAr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618775372253,"user_tz":-120,"elapsed":322411,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"228d5bd8-1195-4c1d-b05d-04081bf51395"},"source":["path = \"/content/drive/MyDrive/Colab Notebooks/Deep Learning/3. Embeddings/\"\n","\n","df = pd.read_csv(path + 'input/simpsons_dataset.csv')\n","df.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(158314, 2)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"_uuid":"c6c6bf4462fb4bc00c2abdbf65eced888219f364","id":"eDl6znPQNpAs","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1618775372254,"user_tz":-120,"elapsed":322406,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"adce00fd-145e-4f18-cea0-264dcc0881a3"},"source":["df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>raw_character_text</th>\n","      <th>spoken_words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Miss Hoover</td>\n","      <td>No, actually, it was a little of both. Sometim...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Lisa Simpson</td>\n","      <td>Where's Mr. Bergstrom?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Miss Hoover</td>\n","      <td>I don't know. Although I'd sure like to talk t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Lisa Simpson</td>\n","      <td>That life is worth living.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Edna Krabappel-Flanders</td>\n","      <td>The polls will be open from now until the end ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        raw_character_text                                       spoken_words\n","0              Miss Hoover  No, actually, it was a little of both. Sometim...\n","1             Lisa Simpson                             Where's Mr. Bergstrom?\n","2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n","3             Lisa Simpson                         That life is worth living.\n","4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"_uuid":"caf6838463d56f79e92d87d5a3827fcd5f04fc54","id":"6bMA63DLNpAs"},"source":["Los valores desconocidos provienen de la parte del diálogo donde algo sucede, pero no hay diálogo. Por ejemplo \"(Springfield Elementary School: EXT. ELEMENTARY - SCHOOL PLAYGROUND - AFTERNOON)\""]},{"cell_type":"code","metadata":{"_uuid":"3a15727caeba1c8d10573456640d0b8b9f2f2e2d","id":"D-oMPhndNpAt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618775372254,"user_tz":-120,"elapsed":322399,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"966278f6-d25d-40c7-e569-d2c0f9f26b8c"},"source":["df.isnull().sum()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["raw_character_text    17814\n","spoken_words          26459\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"_uuid":"885a555596d7484841ea54c94405d03d90572396","id":"VellZdr9NpAt"},"source":["Se eliminan los valores nulos"]},{"cell_type":"code","metadata":{"_uuid":"82cb38f176526679f66ee31e11cfe4f5eebdab51","id":"_B5BYKd_NpAt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618775372255,"user_tz":-120,"elapsed":322392,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"f2d12888-126e-4156-90d6-f57092a2193c"},"source":["df = df.dropna().reset_index(drop=True)\n","df.isnull().sum()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["INFO - 19:49:32: NumExpr defaulting to 2 threads.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["raw_character_text    0\n","spoken_words          0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"_uuid":"7f07dca2a2656dcd9e0c315afa36af32a992eef7","id":"FTKJTQ-JNpAu"},"source":["## Limpieza\n","Se lematiza, se eliminan stop-words y filtra los caracteres no provenientes del alfabeto de cada diálogo\n","\n","- Stemmer: https://medium.com/@tusharsri/nlp-a-quick-guide-to-stemming-60f1ca5db49e\n","- Lemmatizer: https://medium.com/@tusharsri/lemmatization-af85aa3e5a86"]},{"cell_type":"code","metadata":{"_uuid":"b26a0c01c5701630d3951cfc808a9d944eea6371","scrolled":true,"id":"9y-6XLvyNpAu","executionInfo":{"status":"ok","timestamp":1618775373360,"user_tz":-120,"elapsed":323491,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n","\n","def cleaning(doc):\n","    # Lematiza y elimina stopwords\n","    # - Los doc necesitan ser objetos Doc de spacy\n","    txt = [token.lemma_ for token in doc if not token.is_stop]\n","    \n","    # Se filtran los diálogos con menos de 3 palabras debido a que se puede aprender poco de ellos\n","    if len(txt) > 2:\n","        return ' '.join(txt)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"f686964722eede40e5961cd232aee7b6dd587bd1","id":"RntpL_u2NpAu"},"source":["Filtra los caracteres no provenientes del alfabeto"]},{"cell_type":"code","metadata":{"_uuid":"b45598934171607242ca7d50f8c5f7c91411aace","id":"IC_G7ybfNpAv","executionInfo":{"status":"ok","timestamp":1618775373363,"user_tz":-120,"elapsed":323491,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"2360160a7f326a32d56f2f18782d7ce2f4ac1def","id":"xAtCNhVfNpAv"},"source":["Se utiliza la función .pipe() de SpaCy para acelerar el proceso de limpieza"]},{"cell_type":"code","metadata":{"_uuid":"fa44ca458c970ca229426779e6ffcd46c2de313c","id":"M0Dyw7KqNpAw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778290919,"user_tz":-120,"elapsed":3241045,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"b0b57352-ad72-4efa-81d8-22437afaa830"},"source":["t = time()\n","\n","txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n","\n","print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Time to clean up everything: 48.63 mins\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"65ec76c60f9fe93bba6909f4e696f90e3e54710b","id":"SWqGxVM6NpAw"},"source":["Poner los resultados en un dataframe para eliminar los valores vacíos y los duplicados"]},{"cell_type":"code","metadata":{"_uuid":"57f1eb8382554bc592d48915a903230b5b6d6cf7","id":"qUewgekuNpAw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778290920,"user_tz":-120,"elapsed":3241044,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"17b537fb-14f1-4eeb-f7e9-5bbb87738e6b"},"source":["df_clean = pd.DataFrame({'clean': txt})\n","df_clean = df_clean.dropna().drop_duplicates()\n","df_clean.shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(85964, 1)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"_uuid":"31b4a744059df490ddb47ab6cdec008dc929ede3","id":"0mXZvmjjNpAx"},"source":["## Bigramas\n","Utilizamos el paquete de Gensim Phrases para automáticamente detectar frases de dos palabras comunes (bigramas) de una lista de sentencias.\n","https://radimrehurek.com/gensim/models/phrases.html\n","\n","La mayor razón por la que hacemos esto es para detectar palabras como \"mr_burns\" or \"bart_simpson\" !"]},{"cell_type":"code","metadata":{"_uuid":"af6d420284a0ff7a7407d4c526754ffe850d6170","id":"RctR59HHNpAx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778291976,"user_tz":-120,"elapsed":3242098,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"92f42846-b7b5-4a0c-af35-c193ebfe664c"},"source":["from gensim.models.phrases import Phrases, Phraser"],"execution_count":13,"outputs":[{"output_type":"stream","text":["INFO - 20:38:11: 'pattern' package not found; tag filters are not available for English\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"_uuid":"788aec3c82788101db25d4ca6105ee133fecae7c","id":"K7dITcUdNpAy"},"source":["Se necesita pre-procesar. `Phrases()` toma una lista de palabras como entrada "]},{"cell_type":"code","metadata":{"_uuid":"f58487ff08d8812622fd7aef36139f1c850add18","id":"aLyzFyePNpAy","executionInfo":{"status":"ok","timestamp":1618778291976,"user_tz":-120,"elapsed":3242095,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["sent = [row.split() for row in df_clean['clean']]"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"bb7766b322cbc1d3381912b890585eb249ac5304","id":"J9_Nelk9NpAy"},"source":["Crea bigramas interesantes"]},{"cell_type":"code","metadata":{"_uuid":"8befad8c76c54bd2b831b0942a2f626f7d8a6dac","id":"0n4SUbR5NpAy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778293343,"user_tz":-120,"elapsed":3243460,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"25609e6a-267d-4953-cf70-ee09546d62dd"},"source":["phrases = Phrases(sent, min_count=30, progress_per=10000)\n","phrases"],"execution_count":15,"outputs":[{"output_type":"stream","text":["INFO - 20:38:11: collecting all words and their counts\n","INFO - 20:38:11: PROGRESS: at sentence #0, processed 0 words and 0 word types\n","INFO - 20:38:11: PROGRESS: at sentence #10000, processed 63561 words and 52816 word types\n","INFO - 20:38:12: PROGRESS: at sentence #20000, processed 130943 words and 99866 word types\n","INFO - 20:38:12: PROGRESS: at sentence #30000, processed 192972 words and 138532 word types\n","INFO - 20:38:12: PROGRESS: at sentence #40000, processed 249842 words and 172659 word types\n","INFO - 20:38:12: PROGRESS: at sentence #50000, processed 311265 words and 208566 word types\n","INFO - 20:38:12: PROGRESS: at sentence #60000, processed 373588 words and 243702 word types\n","INFO - 20:38:12: PROGRESS: at sentence #70000, processed 436441 words and 278740 word types\n","INFO - 20:38:12: PROGRESS: at sentence #80000, processed 497829 words and 311886 word types\n","INFO - 20:38:13: collected 330804 word types from a corpus of 537160 words (unigram + bigrams) and 85964 sentences\n","INFO - 20:38:13: using 330804 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<gensim.models.phrases.Phrases at 0x7ffa1cb85d10>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"_uuid":"45bae4a953f2ad8951e4efb234e1e357857a33b3","id":"egGJugUCNpAz"},"source":["El objetivo de Phraser() es reducir el consumo de memoria de Phrases(). Mediante el descarte de los estados del modelo que no son interesantes para el aprendizaje del modelo."]},{"cell_type":"code","metadata":{"_kg_hide-input":true,"_uuid":"b8ae81ba230013aefe7c584338de7376fedf6294","id":"6SdqZ2ErNpAz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778296890,"user_tz":-120,"elapsed":3247005,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"e5bd5c6e-a92c-4f08-f077-06bc7208bb10"},"source":["bigram = Phraser(phrases)\n","bigram"],"execution_count":16,"outputs":[{"output_type":"stream","text":["INFO - 20:38:13: source_vocab length 330804\n","INFO - 20:38:16: Phraser built with 126 126 phrasegrams\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<gensim.models.phrases.Phraser at 0x7ffa1bbebd10>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"_uuid":"4a58380f19d159688aeee665d1afb96289fdd4b8","id":"410F0isUNpAz"},"source":["Transformar el corpus en base a los bigramas detectados"]},{"cell_type":"code","metadata":{"_uuid":"8051b56890c147119db3df529d3cfd3cf675fdca","id":"QlOA6QgRNpAz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778296890,"user_tz":-120,"elapsed":3247003,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"7d74e261-d5c7-4116-d88d-13a3bffaa0fc"},"source":["sentences = bigram[sent]\n","sentences"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<gensim.interfaces.TransformedCorpus at 0x7ffa1cb85a10>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"_uuid":"a4f81e8bb2c09a67b00cd24db28353eca8ae188c","id":"Oj3Dl8QdNpA0"},"source":["## Palabras más frecuentes\n","Para asegurar la calidad del trabajo previo"]},{"cell_type":"code","metadata":{"_uuid":"eeb8afe1cfcb7ba65bd14d657455600acacf39ba","id":"4rnMT79TNpA0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778298900,"user_tz":-120,"elapsed":3249010,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"9bbfc25d-80ec-4d0e-d6d0-c3611ebdf371"},"source":["word_freq = defaultdict(int)\n","for sent in sentences:\n","    for i in sent:\n","        word_freq[i] += 1\n","len(word_freq)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30178"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"_uuid":"5b010149150b2b2eaf332d79bcde0649b8a3c2b5","id":"miTj9SU3NpA0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778298900,"user_tz":-120,"elapsed":3249008,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"7aa057e9-1d79-4bd1-c4ec-df2684532707"},"source":["sorted(word_freq, key=word_freq.get, reverse=True)[:10]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['oh', 'like', 'know', 'get', 'hey', 'think', 'right', 'look', 'want', 'come']"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"_uuid":"500ab7b5c84dc006d7945f339c40725a82856fdf","id":"XxYE6gelNpA1"},"source":["# Entrenamiento del modelo\n","## Implementación Word2Vec de Gensim\n","Implementación Word2Vec de Gensim: https://radimrehurek.com/gensim/models/word2vec.html"]},{"cell_type":"code","metadata":{"_uuid":"3269be205cadbad499aa87890893d92da6adc796","id":"cugHzlIZNpA2","executionInfo":{"status":"ok","timestamp":1618778298901,"user_tz":-120,"elapsed":3249007,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["import multiprocessing\n","\n","from gensim.models import Word2Vec"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"7c524bc49c41a6c37f9e754a38797c9501202090","id":"kvedOwYsNpA3"},"source":["## Se separa el entrenamiento en tres pasos:\n","\n","1. `Word2Vec()`: \n",">En este primero paso, se inicializan los parámetros del modelo uno por uno. <br>No se inicializan los parámetros `sentences`, y por ello se deja el modelo sin inicializar.\n","2. `.build_vocab()`: \n",">En este punto se construye el vocabulario de una secuencia de frases y por tanto se inicializa el modelo.<br> Mediante los logs, se puede ver el progreso y más importante aún, el efecto de `min_count` y `sample` en el corpus de palabras. En particular los parámetros `sample` y `min_count` tienen una gran importancia en el modelo. Mostrar ambos permite un manejo más sencillo de su influencia.\n","\n","3. `.train()`:\n",">Finalmente se entrena el modelo.<br>\n","Los Logs se utilizan para monitorizar que varios threads no se ejecutan simultaneamente"]},{"cell_type":"code","metadata":{"_uuid":"03488d9b68963579c96094aca88a302c9f2753a7","id":"ttxpSTe5NpA4","executionInfo":{"status":"ok","timestamp":1618778298901,"user_tz":-120,"elapsed":3249004,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["cores = multiprocessing.cpu_count() # Count the number of cores in a computer"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"89c305fcd163488441ac2ac6133678bd973b4419","id":"TLYrHH4YNpA4"},"source":["## Los parámetros:\n","\n","* `min_count` <font color='purple'>=</font> <font color='green'>int</font> - Filtra todas las palabras con una frecuencia menor que la fijada - (2, 100)\n","\n","\n","* `window` <font color='purple'>=</font> <font color='green'>int</font> - Distancia máxima entre la palabra actual y la palabra a predecir - (2, 10)\n","\n","\n","* `size` <font color='purple'>=</font> <font color='green'>int</font> - Dimensionalidad del embedding - (50, 300)\n","\n","\n","* `sample` <font color='purple'>=</font> <font color='green'>float</font> - Parámetro para reducir el entrenamiento con palabras con alta frecuencia de aparición.  - (0, 1e-5)\n","\n","\n","* `alpha` <font color='purple'>=</font> <font color='green'>float</font> - Learning Rate inicial - (0.01, 0.05)\n","\n","\n","* `min_alpha` <font color='purple'>=</font> <font color='green'>float</font> - Learning rate mínimo al que se puede llegar durante el entrenamiento. Para fijar el descenso de aprendizaje: alpha - (min_alpha * epochs) ~ 0.00\n","\n","\n","* `negative` <font color='purple'>=</font> <font color='green'>int</font> - Si > 0, se va a utilizar negative sampling, el int para valores negativos especifica el número de \"noise words\" que se deberían utilizar. Si = 0, no se utiliza negative sampling. - (5, 20)\n","\n","\n","* `workers` <font color='purple'>=</font> <font color='green'>int</font> - Número de cores que utilizar"]},{"cell_type":"code","metadata":{"_uuid":"ad619db82c219d6cb81fad516563feb0c4d474cd","id":"hgwF5kOPNpA4","executionInfo":{"status":"ok","timestamp":1618778298901,"user_tz":-120,"elapsed":3249001,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["w2v_model = Word2Vec(min_count=20,\n","                     window=2,\n","                     size=300,\n","                     sample=6e-5, \n","                     alpha=0.03, \n","                     min_alpha=0.0007, \n","                     negative=20,\n","                     workers=cores-1)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"d7e9f1bd338f9e15647b5209ffd8fbb131cd7ee5","id":"cyLXiLkeNpA4"},"source":["## Escritura de la Tabla Vocabulario:\n","Word2Vec requires us to build the vocabulary table (simply digesting all the words and filtering out the unique words, and doing some basic counts on them):"]},{"cell_type":"code","metadata":{"_uuid":"66358ad743e05e17dfbed3899af9c41056143daa","id":"rUBlCXlINpA5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778301919,"user_tz":-120,"elapsed":3252016,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"22fbac80-f56b-48ec-85d1-f9243be670f0"},"source":["t = time()\n","\n","w2v_model.build_vocab(sentences, progress_per=10000)\n","\n","print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["INFO - 20:38:18: collecting all words and their counts\n","INFO - 20:38:18: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n","INFO - 20:38:18: PROGRESS: at sentence #10000, processed 61718 words, keeping 9558 word types\n","INFO - 20:38:19: PROGRESS: at sentence #20000, processed 127351 words, keeping 14506 word types\n","INFO - 20:38:19: PROGRESS: at sentence #30000, processed 187829 words, keeping 17619 word types\n","INFO - 20:38:19: PROGRESS: at sentence #40000, processed 243332 words, keeping 20385 word types\n","INFO - 20:38:19: PROGRESS: at sentence #50000, processed 303182 words, keeping 22878 word types\n","INFO - 20:38:20: PROGRESS: at sentence #60000, processed 363940 words, keeping 25200 word types\n","INFO - 20:38:20: PROGRESS: at sentence #70000, processed 425408 words, keeping 27401 word types\n","INFO - 20:38:20: PROGRESS: at sentence #80000, processed 485464 words, keeping 29275 word types\n","INFO - 20:38:20: collected 30178 word types from a corpus of 523700 raw words and 85964 sentences\n","INFO - 20:38:20: Loading a fresh vocabulary\n","INFO - 20:38:20: min_count=20 retains 3319 unique words (10% of original 30178, drops 26859)\n","INFO - 20:38:20: min_count=20 leaves 437324 word corpus (83% of original 523700, drops 86376)\n","INFO - 20:38:20: deleting the raw counts dictionary of 30178 items\n","INFO - 20:38:20: sample=6e-05 downsamples 1200 most-common words\n","INFO - 20:38:20: downsampling leaves estimated 199161 word corpus (45.5% of prior 437324)\n","INFO - 20:38:20: estimated required memory for 3319 words and 300 dimensions: 9625100 bytes\n","INFO - 20:38:20: resetting layer weights\n"],"name":"stderr"},{"output_type":"stream","text":["Time to build vocab: 0.05 mins\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"63260d82061abb47db7f2f8b23e07ec629adf5a9","id":"iHSTRK-FNpA5"},"source":["## Entrenamiento del modelo:\n","_Parámetros del entrenamiento:_\n","* `total_examples` <font color='purple'>=</font> <font color='green'>int</font> - Contador de sentencias;\n","* `epochs` <font color='purple'>=</font> <font color='green'>int</font> - Número de iteracciones (epochs) sobre el corpus corpus - [10, 20, 30]"]},{"cell_type":"code","metadata":{"_uuid":"07a2a047e701e512fd758edff186daadaeea6461","scrolled":true,"id":"_GKBSOlcNpA5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778392627,"user_tz":-120,"elapsed":3342721,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"272605b3-5e12-4808-8aa1-606bb8cc2711"},"source":["t = time()\n","\n","w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n","\n","print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["INFO - 20:38:21: training model with 1 workers on 3319 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n","INFO - 20:38:22: EPOCH 1 - PROGRESS: at 31.39% examples, 63618 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:38:23: EPOCH 1 - PROGRESS: at 67.17% examples, 65323 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:24: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:24: EPOCH - 1 : training on 523700 raw words (198820 effective words) took 3.0s, 66227 effective words/s\n","INFO - 20:38:25: EPOCH 2 - PROGRESS: at 33.37% examples, 64205 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:26: EPOCH 2 - PROGRESS: at 67.17% examples, 64438 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:27: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:27: EPOCH - 2 : training on 523700 raw words (199218 effective words) took 3.0s, 66397 effective words/s\n","INFO - 20:38:28: EPOCH 3 - PROGRESS: at 29.42% examples, 58957 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:29: EPOCH 3 - PROGRESS: at 65.21% examples, 62732 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:30: EPOCH 3 - PROGRESS: at 99.32% examples, 64563 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:38:30: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:30: EPOCH - 3 : training on 523700 raw words (199222 effective words) took 3.1s, 64710 effective words/s\n","INFO - 20:38:31: EPOCH 4 - PROGRESS: at 33.37% examples, 64773 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:38:32: EPOCH 4 - PROGRESS: at 69.05% examples, 65408 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:33: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:33: EPOCH - 4 : training on 523700 raw words (199150 effective words) took 3.0s, 66862 effective words/s\n","INFO - 20:38:34: EPOCH 5 - PROGRESS: at 33.37% examples, 66117 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:35: EPOCH 5 - PROGRESS: at 69.05% examples, 66881 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:36: EPOCH 5 - PROGRESS: at 99.32% examples, 64784 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:38:36: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:36: EPOCH - 5 : training on 523700 raw words (199540 effective words) took 3.1s, 64909 effective words/s\n","INFO - 20:38:37: EPOCH 6 - PROGRESS: at 33.37% examples, 65153 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:38:38: EPOCH 6 - PROGRESS: at 69.05% examples, 65770 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:39: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:39: EPOCH - 6 : training on 523700 raw words (199462 effective words) took 3.0s, 66782 effective words/s\n","INFO - 20:38:40: EPOCH 7 - PROGRESS: at 31.39% examples, 63719 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:41: EPOCH 7 - PROGRESS: at 67.17% examples, 65862 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:42: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:42: EPOCH - 7 : training on 523700 raw words (199000 effective words) took 3.0s, 66729 effective words/s\n","INFO - 20:38:43: EPOCH 8 - PROGRESS: at 33.37% examples, 65054 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:38:44: EPOCH 8 - PROGRESS: at 65.21% examples, 63001 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:45: EPOCH 8 - PROGRESS: at 99.32% examples, 64591 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:38:45: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:45: EPOCH - 8 : training on 523700 raw words (199266 effective words) took 3.1s, 64740 effective words/s\n","INFO - 20:38:46: EPOCH 9 - PROGRESS: at 33.37% examples, 64881 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:47: EPOCH 9 - PROGRESS: at 69.05% examples, 65685 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:38:48: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:48: EPOCH - 9 : training on 523700 raw words (199201 effective words) took 3.0s, 66780 effective words/s\n","INFO - 20:38:49: EPOCH 10 - PROGRESS: at 33.37% examples, 65911 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:38:50: EPOCH 10 - PROGRESS: at 69.05% examples, 67085 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:51: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:51: EPOCH - 10 : training on 523700 raw words (199075 effective words) took 2.9s, 67536 effective words/s\n","INFO - 20:38:52: EPOCH 11 - PROGRESS: at 31.39% examples, 63159 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:53: EPOCH 11 - PROGRESS: at 63.30% examples, 61841 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:54: EPOCH 11 - PROGRESS: at 97.45% examples, 64001 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:54: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:54: EPOCH - 11 : training on 523700 raw words (199385 effective words) took 3.1s, 64398 effective words/s\n","INFO - 20:38:55: EPOCH 12 - PROGRESS: at 31.39% examples, 63254 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:57: EPOCH 12 - PROGRESS: at 67.17% examples, 64884 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:38:57: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:38:57: EPOCH - 12 : training on 523700 raw words (198819 effective words) took 3.0s, 66449 effective words/s\n","INFO - 20:38:58: EPOCH 13 - PROGRESS: at 33.37% examples, 65881 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:00: EPOCH 13 - PROGRESS: at 69.05% examples, 66174 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:00: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:00: EPOCH - 13 : training on 523700 raw words (199107 effective words) took 3.0s, 67174 effective words/s\n","INFO - 20:39:01: EPOCH 14 - PROGRESS: at 33.37% examples, 65094 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:03: EPOCH 14 - PROGRESS: at 65.21% examples, 62435 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:04: EPOCH 14 - PROGRESS: at 100.00% examples, 64720 words/s, in_qsize 0, out_qsize 1\n","INFO - 20:39:04: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:04: EPOCH - 14 : training on 523700 raw words (199018 effective words) took 3.1s, 64592 effective words/s\n","INFO - 20:39:05: EPOCH 15 - PROGRESS: at 31.39% examples, 64255 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:06: EPOCH 15 - PROGRESS: at 67.17% examples, 66054 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:07: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:07: EPOCH - 15 : training on 523700 raw words (199635 effective words) took 3.0s, 67025 effective words/s\n","INFO - 20:39:08: EPOCH 16 - PROGRESS: at 33.37% examples, 64962 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:09: EPOCH 16 - PROGRESS: at 69.05% examples, 66112 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:09: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:09: EPOCH - 16 : training on 523700 raw words (199205 effective words) took 3.0s, 67153 effective words/s\n","INFO - 20:39:11: EPOCH 17 - PROGRESS: at 33.37% examples, 58204 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:12: EPOCH 17 - PROGRESS: at 70.95% examples, 62944 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:13: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:13: EPOCH - 17 : training on 523700 raw words (199196 effective words) took 3.1s, 64686 effective words/s\n","INFO - 20:39:14: EPOCH 18 - PROGRESS: at 33.37% examples, 63985 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:15: EPOCH 18 - PROGRESS: at 69.05% examples, 66023 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:16: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:16: EPOCH - 18 : training on 523700 raw words (199097 effective words) took 3.0s, 67259 effective words/s\n","INFO - 20:39:17: EPOCH 19 - PROGRESS: at 33.37% examples, 66195 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:18: EPOCH 19 - PROGRESS: at 69.05% examples, 66132 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:19: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:19: EPOCH - 19 : training on 523700 raw words (199697 effective words) took 3.0s, 67342 effective words/s\n","INFO - 20:39:20: EPOCH 20 - PROGRESS: at 29.42% examples, 58844 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:21: EPOCH 20 - PROGRESS: at 65.21% examples, 62468 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:22: EPOCH 20 - PROGRESS: at 100.00% examples, 64957 words/s, in_qsize 0, out_qsize 1\n","INFO - 20:39:22: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:22: EPOCH - 20 : training on 523700 raw words (199491 effective words) took 3.1s, 64802 effective words/s\n","INFO - 20:39:23: EPOCH 21 - PROGRESS: at 31.39% examples, 63813 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:24: EPOCH 21 - PROGRESS: at 69.05% examples, 65709 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:25: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:25: EPOCH - 21 : training on 523700 raw words (198582 effective words) took 3.0s, 67005 effective words/s\n","INFO - 20:39:26: EPOCH 22 - PROGRESS: at 33.37% examples, 65402 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:27: EPOCH 22 - PROGRESS: at 69.05% examples, 65526 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:28: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:28: EPOCH - 22 : training on 523700 raw words (199255 effective words) took 3.0s, 66588 effective words/s\n","INFO - 20:39:29: EPOCH 23 - PROGRESS: at 29.42% examples, 58321 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:30: EPOCH 23 - PROGRESS: at 65.21% examples, 62322 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:31: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:31: EPOCH - 23 : training on 523700 raw words (199012 effective words) took 3.1s, 64931 effective words/s\n","INFO - 20:39:32: EPOCH 24 - PROGRESS: at 31.39% examples, 63888 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:33: EPOCH 24 - PROGRESS: at 67.17% examples, 65911 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:34: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:34: EPOCH - 24 : training on 523700 raw words (198827 effective words) took 3.0s, 66779 effective words/s\n","INFO - 20:39:35: EPOCH 25 - PROGRESS: at 33.37% examples, 63983 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:36: EPOCH 25 - PROGRESS: at 69.05% examples, 65585 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:37: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:37: EPOCH - 25 : training on 523700 raw words (199315 effective words) took 3.0s, 67029 effective words/s\n","INFO - 20:39:38: EPOCH 26 - PROGRESS: at 29.42% examples, 58740 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:39: EPOCH 26 - PROGRESS: at 65.21% examples, 62559 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:40: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:40: EPOCH - 26 : training on 523700 raw words (199170 effective words) took 3.1s, 65021 effective words/s\n","INFO - 20:39:41: EPOCH 27 - PROGRESS: at 33.37% examples, 65058 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:42: EPOCH 27 - PROGRESS: at 69.05% examples, 65946 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:43: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:43: EPOCH - 27 : training on 523700 raw words (199503 effective words) took 3.0s, 67213 effective words/s\n","INFO - 20:39:44: EPOCH 28 - PROGRESS: at 33.37% examples, 65428 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:45: EPOCH 28 - PROGRESS: at 69.05% examples, 66340 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:46: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:46: EPOCH - 28 : training on 523700 raw words (199304 effective words) took 3.0s, 67062 effective words/s\n","INFO - 20:39:47: EPOCH 29 - PROGRESS: at 33.37% examples, 65882 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:48: EPOCH 29 - PROGRESS: at 65.21% examples, 62538 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:49: EPOCH 29 - PROGRESS: at 99.32% examples, 64286 words/s, in_qsize 1, out_qsize 0\n","INFO - 20:39:49: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:49: EPOCH - 29 : training on 523700 raw words (199329 effective words) took 3.1s, 64437 effective words/s\n","INFO - 20:39:50: EPOCH 30 - PROGRESS: at 33.37% examples, 65783 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:51: EPOCH 30 - PROGRESS: at 69.05% examples, 66244 words/s, in_qsize 0, out_qsize 0\n","INFO - 20:39:52: worker thread finished; awaiting finish of 0 more threads\n","INFO - 20:39:52: EPOCH - 30 : training on 523700 raw words (198902 effective words) took 3.0s, 67084 effective words/s\n","INFO - 20:39:52: training on a 15711000 raw words (5975803 effective words) took 90.7s, 65902 effective words/s\n"],"name":"stderr"},{"output_type":"stream","text":["Time to train the model: 1.51 mins\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"48e12768512b82c2d5cf6a543e3a9f2515699a22","id":"rnG5meDtNpA6"},"source":["Dado que no queremos entrenar el modelo más, utilizamos la función init_sims(), que hace el modelo mucho más eficiente en su uso de memoria:"]},{"cell_type":"code","metadata":{"_uuid":"34dd51c7f2f39d016b982ef81e4df576f6b31bcb","id":"AcUm7CNMNpA7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778392628,"user_tz":-120,"elapsed":3342720,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"48085ff8-911f-44f4-9621-82b874f4e4bd"},"source":["w2v_model.init_sims(replace=True)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["INFO - 20:39:52: precomputing L2-norms of word weight vectors\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"_uuid":"a420d5a98eb860cff1f4bbac8cbe2054459b6200","id":"0wOXj8HtNpA7"},"source":["# Explorando el modelo\n","## Más similar a:\n","\n","Aquí, le preguntamos al modelo que encuentre la palabra más similar a alguno de los mayores iconos de los Simpsons!"]},{"cell_type":"markdown","metadata":{"_uuid":"a8f3cfd8ac88978a4df31c90afa194bd6fa4f3f5","id":"2xw0aI-lNpA7"},"source":["<img src=\"https://vignette.wikia.nocookie.net/simpsons/images/0/02/Homer_Simpson_2006.png/revision/latest?cb=20091207194310\" alt=\"drawing\" width=\"130\"/>\n","\n","Veamos lo que conseguimos con protagonista principal!"]},{"cell_type":"code","metadata":{"_uuid":"339207a733a1ac42fe60e32a29f9e5d5ca0a9275","id":"iaD7hrJANpA7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778392628,"user_tz":-120,"elapsed":3342717,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"58d40fb1-e945-4a27-ca7d-5435dfb756ef"},"source":["w2v_model.wv.most_similar(positive=[\"homer\"])"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('bongo', 0.7772750854492188),\n"," ('marge', 0.7608616352081299),\n"," ('rude', 0.7566046118736267),\n"," ('wife', 0.7553014755249023),\n"," ('snuggle', 0.7500259876251221),\n"," ('sweetheart', 0.748281717300415),\n"," ('gee', 0.7425020933151245),\n"," ('crummy', 0.7420293092727661),\n"," ('sorry', 0.7347474098205566),\n"," ('worry', 0.7290295362472534)]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"_uuid":"3b6686e6fa956a98450259b063b4cf51019a6d0b","id":"2Fw5J_LnNpA7"},"source":["_Pequeña puntuación:_<br>\n","El conjunto de datos es la línea de diálogo de los Simpson; por lo tanto, cuando miramos las palabras más parecidas de \"homer\" no es necesario obtener los miembros de su familia, los rasgos de su personalidad, o incluso sus palabras más citadas. No, obtenemos lo que otros personajes (como Homer no se refiere a menudo a sí mismo en tercera persona) dijeron junto con \"homer\", como cómo se siente o se ve (\"deprimido\"), dónde está (\"hamaca\"), o con quién (\"marge\").\n","\n","Veamos lo que el bigrama \"homer_simpson\" nos da en comparación:"]},{"cell_type":"code","metadata":{"_uuid":"23e5149b19f18f4f2f456d4c72afc5c188bcfba4","id":"zspwSowUNpA8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778392629,"user_tz":-120,"elapsed":3342716,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"56650391-b809-4c26-964a-0330c3e83ea4"},"source":["w2v_model.wv.most_similar(positive=[\"homer_simpson\"])"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('congratulation', 0.7782440781593323),\n"," ('recent', 0.7706798315048218),\n"," ('council', 0.7668615579605103),\n"," ('easily', 0.763874888420105),\n"," ('governor', 0.7603208422660828),\n"," ('hutz', 0.7457172870635986),\n"," ('committee', 0.7440746426582336),\n"," ('erotic', 0.742489218711853),\n"," ('simon', 0.734795331954956),\n"," ('viewer', 0.7345239520072937)]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"_uuid":"0e3e121e022f2f659cf97bba42cecd3f3c9afb01","id":"dkAdhTzwNpA8"},"source":["<img src=\"https://vignette.wikia.nocookie.net/simpsons/images/0/0b/Marge_Simpson.png/revision/latest?cb=20180626055729\" alt=\"drawing\" width=\"150\"/>\n","\n","¿Qué pasa ahora con Marge?"]},{"cell_type":"code","metadata":{"_uuid":"22595f98c675a9697243b7e826b2840e5fc3e5f5","id":"_44Y9Q1JNpA8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778392629,"user_tz":-120,"elapsed":3342714,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"d9d500c7-6d61-44d9-cd50-882f7fcf3b4a"},"source":["w2v_model.wv.most_similar(positive=[\"marge\"])"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('convince', 0.7752747535705566),\n"," ('rude', 0.7635070085525513),\n"," ('homer', 0.7608615756034851),\n"," ('ralphie', 0.7571084499359131),\n"," ('sorry', 0.755699098110199),\n"," ('becky', 0.7554717659950256),\n"," ('grownup', 0.7534979581832886),\n"," ('darling', 0.750558614730835),\n"," ('sure', 0.750037431716919),\n"," ('raccoon', 0.7488826513290405)]"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"_uuid":"2b4857ff1159695c72c22417cf52dc84e0dfc9ea","id":"Ar0JWwtBNpA8"},"source":["<img src=\"https://vignette.wikia.nocookie.net/simpsons/images/6/65/Bart_Simpson.png/revision/latest?cb=20180319061933\" alt=\"drawing\" width=\"100\"/>\n","\n","Veamos a Bart ahora"]},{"cell_type":"code","metadata":{"_uuid":"ac9ba47738e596dce6552099e76f303f28577943","id":"V1-NBHi_NpA8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618778392630,"user_tz":-120,"elapsed":3342713,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"f7b1075d-cecf-4e91-9ce7-78b41d735089"},"source":["w2v_model.wv.most_similar(positive=[\"bart\"])"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('lisa', 0.839928925037384),\n"," ('homework', 0.7986600399017334),\n"," ('surprised', 0.7944226861000061),\n"," ('mom', 0.790746808052063),\n"," ('convince', 0.7826062440872192),\n"," ('upset', 0.7788929343223572),\n"," ('typical', 0.7725905179977417),\n"," ('substitute', 0.7718350887298584),\n"," ('hearing', 0.769727349281311),\n"," ('strangle', 0.7668836116790771)]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"_uuid":"c9afcf59e71f797f8e4d6d4b4ce39e359b19a450","id":"m_ZU1AD_NpA9"},"source":["Parece que tiene sentido\n","\n","<img src=\"https://vignette.wikia.nocookie.net/simpsons/images/9/9d/Groundskeeper_Willie.png/revision/latest?cb=20130424154035\" alt=\"drawing\" width=\"150\"/>\n","\n","Dejemos a Willie como último"]},{"cell_type":"markdown","metadata":{"_uuid":"d8b5937dfd7584f168a33060c435036cad5b390b","id":"HBiPUm5HNpA9"},"source":["## Similaridades:\n","Here, we will see how similar are two words to each other :"]},{"cell_type":"code","metadata":{"_uuid":"367755f5c9e00de4bc5056c978f5b50a38c1368b","id":"GdWX_JgxNpA9","colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"status":"error","timestamp":1618786819251,"user_tz":-120,"elapsed":1602,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}},"outputId":"be760097-f3dc-47a8-91ab-ff9b1f3514e0"},"source":["w2v_model.wv.similarity(\"moe_'s\", 'tavern')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d708a3e008aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"moe_'s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tavern'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'w2v_model' is not defined"]}]},{"cell_type":"markdown","metadata":{"_uuid":"d31383aa2f6310a38ec671f2ca4b0fcb195551dd","id":"l5KMg0m1NpA9"},"source":["Who could forget Moe's tavern? Not Barney.\n","\n","<img src=\"https://vignette.wikia.nocookie.net/simpsons/images/6/6c/MaggieSimpson.PNG/revision/latest?cb=20180314210204\" alt=\"drawing\" width=\"100\"/>"]},{"cell_type":"code","metadata":{"_uuid":"349828078b5a438d93e5494478e88095913dc58e","id":"oIxAf4yfNpA9","executionInfo":{"status":"aborted","timestamp":1618778392952,"user_tz":-120,"elapsed":3343029,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["w2v_model.wv.similarity('maggie', 'baby')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"7d7842e5b5cab743db56ff120d75ad3974c429d8","id":"niixqFpmNpA9"},"source":["Maggie is indeed the most renown baby in the Simpsons!"]},{"cell_type":"code","metadata":{"_uuid":"9ee5e2532214b20fef0a597bc5ad355762fcc281","id":"gdzLkwWPNpA-","executionInfo":{"status":"aborted","timestamp":1618778392954,"user_tz":-120,"elapsed":3343029,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["w2v_model.wv.similarity('bart', 'nelson')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"08a999d758ac687d626b631a8ce393eaa26f41e7","id":"csX2_bMoNpA-"},"source":["Bart and Nelson, though friends, are not that close, makes sense!\n","\n","## Eliminar un elemento:\n","\n","Aquí, lo que le pedimos al modelo es que nos quite la palabra que no pertenezca a la lista!\n","\n","Entre Jimbo, Milhouse, and Kearney, quien no es un bully?"]},{"cell_type":"code","metadata":{"_uuid":"d982e44d9c212b5ee09bcaebd050a725ab5e508e","id":"sl4z7zwRNpA-","executionInfo":{"status":"aborted","timestamp":1618778392955,"user_tz":-120,"elapsed":3343027,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'kearney'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"12d3c035c89718e70c193f095b46e38dccef6b0d","id":"ijpDPLHJNpA-"},"source":["Claramente Milhouse!\n","<img src=\"https://vignette.wikia.nocookie.net/simpsons/images/9/91/Milhouse_Van_Houten_2.png/revision/latest?cb=20180429212659\" alt=\"drawing\" width=\"150\"/>\n","\n","Qué pasaría en cambio si comparamos la amistad entre Nelson, Bart, and Milhouse?"]},{"cell_type":"code","metadata":{"_uuid":"cafd4a7bec6d6255ea3f5f06df951546c0d783a9","id":"S_mF8WESNpA-","executionInfo":{"status":"aborted","timestamp":1618778392956,"user_tz":-120,"elapsed":3343026,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["w2v_model.wv.doesnt_match([\"nelson\", \"bart\", \"milhouse\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"01c0148dc758db74ed8078ca54e8393ada090c8c","id":"4wQRN9CONpA_"},"source":["Parece que Nelson es el raro!\n","\n","<img src=\"https://vignette.wikia.nocookie.net/simpsons/images/4/40/Picture0003.jpg/revision/latest?cb=20110623042517\" alt=\"drawing\" width=\"200\"/>\n","\n","Por último, cual es la relación entre Homer y sus dos cuñadas?"]},{"cell_type":"code","metadata":{"_uuid":"445912f7d89b3cb1550926be161d134e6689f54f","id":"_hFc5psuNpA_","executionInfo":{"status":"aborted","timestamp":1618778392956,"user_tz":-120,"elapsed":3343023,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["w2v_model.wv.doesnt_match(['homer', 'patty', 'selma'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"df95cdff693e843ab4b4c174fea24029447573cd","id":"8xgVnVy6NpA_"},"source":["Parece que claramente no es Homer!\n","\n","## Diferencia por analogía:\n","Qué palabra es a mujer como Homer es a Marge?"]},{"cell_type":"code","metadata":{"_uuid":"812961e79dde9f2032f708755ca287c0aef838d0","id":"Vh5oAzyINpA_","executionInfo":{"status":"aborted","timestamp":1618778392956,"user_tz":-120,"elapsed":3343021,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["w2v_model.wv.most_similar(positive=[\"woman\", \"homer\"], negative=[\"marge\"], topn=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"5a4ff4a8c8c582c6d9c704a042e8cc5d18b7bd6c","id":"Epv4MsJqNpA_"},"source":["\"man\" viene en primera posición, parece correcto!\n","\n","Qué palabra es a mujer como Bart es a hombre?"]},{"cell_type":"code","metadata":{"_uuid":"4cfef57b94b635abb58a4ff191785506c78ec9d9","id":"QFGbL6dkNpBA","executionInfo":{"status":"aborted","timestamp":1618778392957,"user_tz":-120,"elapsed":3343019,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["w2v_model.wv.most_similar(positive=[\"woman\", \"bart\"], negative=[\"man\"], topn=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"ef520bd7dd974d14afcb8e69266579ac0b703714","id":"JAQpes3xNpBA"},"source":["List es la hermana de Bart, su contraparte masculino!\n","<img src=\"https://vignette.wikia.nocookie.net/simpsons/images/5/57/Lisa_Simpson2.png/revision/latest?cb=20180319000458\" alt=\"drawing\" width=\"100\"/>"]},{"cell_type":"markdown","metadata":{"_uuid":"773c0acc8750ba8e728ff261f2e9ec39694c245c","id":"ksC_CCAgNpBA"},"source":["### T-SNE visualizaciones\n","T-SNE es un algoritmo de reducción de dimensionalidad no lineal que intenta representar datos de una mayor dimensionalidad y mantener las relaciones entre vectores<br>\n","\n","Aquí tenemos un buen tutorial: https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b"]},{"cell_type":"code","metadata":{"_uuid":"27ec46110042fc28da900b1b344ae4e0692d5dc2","id":"l39vacXUNpBA","executionInfo":{"status":"aborted","timestamp":1618778392957,"user_tz":-120,"elapsed":3343016,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n"," \n","import seaborn as sns\n","sns.set_style(\"darkgrid\")\n","\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"22693eaa25253b38cee3c5cd5db6b6fdddb575a4","id":"lHuNjCCrNpBA"},"source":["Nuestro objetivo en esta sección es transformar nuestras 300 dimensiones en 2 dimensiones y descubrir patrones interesantes en los datos.<br>\n","Para este ejemplo se va a utilizar la implementación de scikit-learn.\n","\n","Para hacer las visualizaciones más relevantes, vamos a mirar las relaciones entre la palabra buscada (en <font color='red'>**rojo**</font>), las palabras más similares del modelo en azul (en <font color=\"blue\">**blue**</font>), y otras palabras del vocabulario en verde (en <font color='green'>**green**</font>)."]},{"cell_type":"code","metadata":{"_uuid":"489a7d160dcd92da0ce42a3b5b461368c9ffe5f1","id":"CWs0C8YWNpBB","executionInfo":{"status":"aborted","timestamp":1618778392958,"user_tz":-120,"elapsed":3343015,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["def tsnescatterplot(model, word, list_names):\n","    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n","    its list of most similar words, and a list of words.\n","    \"\"\"\n","    arrays = np.empty((0, 300), dtype='f')\n","    word_labels = [word]\n","    color_list  = ['red']\n","\n","    # adds the vector of the query word\n","    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n","    \n","    # gets list of most similar words\n","    close_words = model.wv.most_similar([word])\n","    \n","    # adds the vector for each of the closest words to the array\n","    for wrd_score in close_words:\n","        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n","        word_labels.append(wrd_score[0])\n","        color_list.append('blue')\n","        arrays = np.append(arrays, wrd_vector, axis=0)\n","    \n","    # adds the vector for each of the words from list_names to the array\n","    for wrd in list_names:\n","        wrd_vector = model.wv.__getitem__([wrd])\n","        word_labels.append(wrd)\n","        color_list.append('green')\n","        arrays = np.append(arrays, wrd_vector, axis=0)\n","        \n","    # Reduces the dimensionality from 300 to 15 dimensions with PCA\n","    reduc = PCA(n_components=15).fit_transform(arrays)\n","    \n","    # Finds t-SNE coordinates for 2 dimensions\n","    np.set_printoptions(suppress=True)\n","    \n","    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n","    \n","    # Sets everything up to plot\n","    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n","                       'y': [y for y in Y[:, 1]],\n","                       'words': word_labels,\n","                       'color': color_list})\n","    \n","    fig, _ = plt.subplots()\n","    fig.set_size_inches(9, 9)\n","    \n","    # Basic plot\n","    p1 = sns.regplot(data=df,\n","                     x=\"x\",\n","                     y=\"y\",\n","                     fit_reg=False,\n","                     marker=\"o\",\n","                     scatter_kws={'s': 40,\n","                                  'facecolors': df['color']\n","                                 }\n","                    )\n","    \n","    # Adds annotations one by one with a loop\n","    for line in range(0, df.shape[0]):\n","         p1.text(df[\"x\"][line],\n","                 df['y'][line],\n","                 '  ' + df[\"words\"][line].title(),\n","                 horizontalalignment='left',\n","                 verticalalignment='bottom', size='medium',\n","                 color=df['color'][line],\n","                 weight='normal'\n","                ).set_size(15)\n","\n","    \n","    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n","    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n","            \n","    plt.title('t-SNE visualization for {}'.format(word.title()))\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"3943c170a5f5f09974d90c89bdb9ec761e63a416","id":"GQ2UKDYzNpBB"},"source":["Código inspirado por: [[2]](#References:)\n","\n","## 10 Palabras más parecidas vs. 8 Palabras al azar:\n","Comparemos donde la representación vectorial de Homero, sus 10 palabras más similares del modelo, así como las 8 aleatorias, se encuentra en un gráfico 2D:"]},{"cell_type":"code","metadata":{"_uuid":"18d788b2a92f94771a5f9485a885d44dfba62a94","id":"Oq7fcaLxNpBB","executionInfo":{"status":"aborted","timestamp":1618778392958,"user_tz":-120,"elapsed":3343012,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["tsnescatterplot(w2v_model, 'homer', ['dog', 'bird', 'ah', 'maude', 'bob', 'mel', 'apu', 'duff'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"c73fc2faaf0baecc84f02a97b50cb9ccefa48686","id":"EgTMIk8dNpBB"},"source":["Curiosamente, las 10 palabras más parecidas a Homero terminan a su alrededor, al igual que Apu y Bob, dos personajes recurrentes.\n","\n","## 10 palabras más similares vs. 10 más disímiles\n","\n","Esta vez, comparemos dónde se encuentra la representación vectorial de Maggie y sus 10 palabras más parecidas del modelo, con la representación vectorial de las 10 palabras más disímiles de Maggie:"]},{"cell_type":"code","metadata":{"_uuid":"10c77b072f7c281f2be919341be116565c20d8a8","id":"Wv1SJ8pPNpBB","executionInfo":{"status":"aborted","timestamp":1618778392959,"user_tz":-120,"elapsed":3343011,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["tsnescatterplot(w2v_model, 'maggie', [i[0] for i in w2v_model.wv.most_similar(negative=[\"maggie\"])])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"87315bfbaceb3733bd7af035db6c59cfc4b1ba7f","id":"stVzmNtfNpBC"},"source":["¡Genial! Maggie y sus palabras más similares forman un grupo distintivo de las palabras más disímiles, ¡es una trama realmente alentadora!\n","\n","## 10 Palabras más similares vs. 11 a 20 Palabras más similares:\n","\n","Por último, vamos a trazar la trama de las palabras más similares al Sr. Burns clasificado del 1 al 10 contra los clasificados del 11 al 20:\n","\n","(PD: El Sr. Burns se convirtió en el Sr. Burns después del pre-procesamiento)"]},{"cell_type":"code","metadata":{"_uuid":"e6f0bc598922f4f2cd17d2511560242a3c35fdd9","id":"V9ZPreyPNpBC","executionInfo":{"status":"aborted","timestamp":1618778392959,"user_tz":-120,"elapsed":3343008,"user":{"displayName":"Inigo Alonso","photoUrl":"https://lh3.googleusercontent.com/-1RGKoE_XRsg/AAAAAAAAAAI/AAAAAAAABOo/9RgCb1JY6wM/s64/photo.jpg","userId":"03508068981052077484"}}},"source":["tsnescatterplot(w2v_model, \"mr_burn\", [t[0] for t in w2v_model.wv.most_similar(positive=[\"mr_burn\"], topn=20)][10:])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"011aa35b717d985f1d9fb820208531222055ff7b","id":"vuXqZAIlNpBC"},"source":["As we can see, and that is very nice, all the 20 words are forming one cluster around Mr. Burns.\n","\n","# Pensamientos finales\n","\n","Espero que hayas encontrado este tutorial útil y te hayas divertido tanto leyéndolo como yo escribiéndolo. Por favor, no duden en dejar cualquier comentario, pregunta o sugerencia que puedan tener. Nos vemos por ahí!\n","\n","También, por favor, comprueben [Supportiv](http://www.supportiv.com) por ahí! (Logotipo en tamaño Simpson)\n","\n","<img src=\"https://fontmeme.com/permalink/180904/cc3d27a8aaa88189e764ee9d02331d0d.png\" alt=\"drawing\" width=\"500\"/>\n","\n","\n","# Materiales para una comprensión más profunda:\n","* Word Embeddings introduction: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n","* Word2Vec introduction: https://skymind.ai/wiki/word2vec\n","* Another Word2Vec introduction: http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n","* A great Gensim implentation tutorial: http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.W467ScBjM2x\n","* Original articles from Mikolov et al.: https://arxiv.org/abs/1301.3781 and https://arxiv.org/abs/1310.4546\n","\n","\n","# Reconocimientos\n","\n","* [Pouria Mojabi](https://www.linkedin.com/in/pouria-mojabi-1873615/), co-fouder of Supportiv Inc.\n","\n","# Referencias:\n","* [1]. Neural Net picture: McCormick, C. (2016, April 19). Word2Vec Tutorial - The Skip-Gram Model. Retrieved from http://www.mccormickml.com\n","* [2]. Aneesha Bakharia Medium article: https://medium.com/@aneesha/using-tsne-to-plot-a-subset-of-similar-words-from-word2vec-bb8eeaea6229\n","\n","# Ejercicios\n","- ¿Qué información podría sacar si entreno el W2V con listas de películas vistas por usuarios?\n","- ¿Podría utilizar los embeddings para detectar productos sustitutivos en supermercados? ¿Qué necesitaría? ¿Cómo se haría?\n","- ¿Qué sucedería si entreno el modelo con textos en distintos idiomas? ¿Podría utilizar los embeddings para determinar cuantos idiomas hay?\n","- OPCIONAL: \n","  - Crear un vector por texto, en vez de por palabra, utilizando la función de Doc2Vec de Gensim.\n","  - ¿Qué resultados salen?\n"]}]}