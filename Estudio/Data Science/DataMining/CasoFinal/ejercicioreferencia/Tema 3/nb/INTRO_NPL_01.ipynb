{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXpLQ-hI_aiD"
   },
   "source": [
    "# Introducción a NPL y extracción de características\n",
    "Para poder aplicar cualquier algoritmo de NLP es necesario convertir el texto en caracteristicas numéricas (modelo *vector space*). Aquí vamos a ver las más comunes:  \n",
    "- Modelo *Bag-of-Words* (BoW)  \n",
    "- Modelo *Term Frequency-Inverse Document Frequency* (TF-IDF)  \n",
    "- Modelo *Word Embeddings* (WE)  \n",
    "\n",
    "Vamos a usar las librerías más comunes para esta tarea, `scikit-learn`, `gensim`, `spaCy`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MjQfSmvx_bGv"
   },
   "outputs": [],
   "source": [
    "# librerías y opciones de entorno\n",
    "%reset -sf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SFIGmSg6lYll"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-lg==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-3.6.0/es_core_news_lg-3.6.0-py3-none-any.whl (568.0 MB)\n",
      "     -------------------------------------- 568.0/568.0 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from es-core-news-lg==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (5.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.28.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.11.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (63.4.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (4.64.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->es-core-news-lg==3.6.0) (2.0.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "# Instalamos la librería y el modelo de lenguaje para el español, solo la primera vez\n",
    "!python -m spacy download es_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7m7Hf6K9mN8B"
   },
   "outputs": [],
   "source": [
    "# Cargamos el modelo de lenguaje para el español\n",
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EU1K5PUj_eg0"
   },
   "outputs": [],
   "source": [
    "# Se define el corpus que vamos a usar\n",
    "corpus = [\n",
    "    \"El conocimiento es poder.\",\n",
    "    \"La perseverancia es la clave del éxito.\",\n",
    "    \"La creatividad es contagiosa, pásala.\",\n",
    "    \"El viaje de mil millas comienza con un solo paso.\",\n",
    "    \"La vida es lo que pasa mientras estás ocupado haciendo otros planes.\",\n",
    "    \"El tiempo es un recurso no renovable, úsalo sabiamente.\",\n",
    "    \"Nunca es tarde para ser lo que podrías haber sido.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGe82JUEAJ3b"
   },
   "source": [
    "## Limpieza del texto\n",
    "Definimos una función simple de limpieza y normalización del texto y la aplicamos a nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3fmPwpdbAFKa"
   },
   "outputs": [],
   "source": [
    "def normalizar_doc(doc):\n",
    "    '''Función que normaliza un texto cogiendo sólo\n",
    "    las palabras en minúsculas que no son stop_words'''\n",
    "    # separamos en tokens\n",
    "    tokens = nlp(doc)\n",
    "    # filtramos stopwords\n",
    "    filtered_tokens = [t.lower_ for t in tokens if\n",
    "                       not t.is_stop and\n",
    "                       not t.is_space and\n",
    "                       not t.is_punct]\n",
    "    # juntamos de nuevo en una cadena\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFvhs3KlAQAi",
    "outputId": "343692e9-4ffe-4a53-bb58-854d750629d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conocimiento',\n",
       " 'perseverancia clave éxito',\n",
       " 'creatividad contagiosa pásala',\n",
       " 'viaje mil millas comienza paso',\n",
       " 'vida pasa estás ocupado planes',\n",
       " 'tiempo recurso renovable úsalo sabiamente',\n",
       " 'podrías']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicamos la función de normalización a todo el Corpus:\n",
    "norm_corpus = [normalizar_doc(doc) for doc in corpus]\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUsLwDcYAXfB"
   },
   "source": [
    "## Modelo Bag-of-Word (BoW)\n",
    "El modelo BoW consiste en contar la frecuencia de aparición de cada término en todos los documentos, usando un diccionario de términos común."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "AqBZuPiqAMzt",
    "outputId": "c7d4cdda-49c7-47d2-f13d-1308684fcdaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iu9SKXYaA8Nj",
    "outputId": "a9431dfd-3cfd-447d-fe06-7dcadbd15b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clave' 'comienza' 'conocimiento' 'contagiosa' 'creatividad' 'estás'\n",
      " 'mil' 'millas' 'ocupado' 'pasa' 'paso' 'perseverancia' 'planes' 'podrías'\n",
      " 'pásala' 'recurso' 'renovable' 'sabiamente' 'tiempo' 'viaje' 'vida'\n",
      " 'éxito' 'úsalo']\n"
     ]
    }
   ],
   "source": [
    "# distintas palabras\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfhYrRwcB0F2",
    "outputId": "98648202-3333-409d-80d1-7d4ec1b94c4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# las convertimos en matriz\n",
    "cv_matrix = cv.transform(norm_corpus)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "j8T9MppIAcRL",
    "outputId": "cc4d8478-c6b5-47c2-cb2d-62100daa98e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clave</th>\n",
       "      <th>comienza</th>\n",
       "      <th>conocimiento</th>\n",
       "      <th>contagiosa</th>\n",
       "      <th>creatividad</th>\n",
       "      <th>estás</th>\n",
       "      <th>mil</th>\n",
       "      <th>millas</th>\n",
       "      <th>ocupado</th>\n",
       "      <th>pasa</th>\n",
       "      <th>...</th>\n",
       "      <th>podrías</th>\n",
       "      <th>pásala</th>\n",
       "      <th>recurso</th>\n",
       "      <th>renovable</th>\n",
       "      <th>sabiamente</th>\n",
       "      <th>tiempo</th>\n",
       "      <th>viaje</th>\n",
       "      <th>vida</th>\n",
       "      <th>éxito</th>\n",
       "      <th>úsalo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clave  comienza  conocimiento  contagiosa  creatividad  estás  mil  millas  \\\n",
       "0      0         0             1           0            0      0    0       0   \n",
       "1      1         0             0           0            0      0    0       0   \n",
       "2      0         0             0           1            1      0    0       0   \n",
       "3      0         1             0           0            0      0    1       1   \n",
       "4      0         0             0           0            0      1    0       0   \n",
       "5      0         0             0           0            0      0    0       0   \n",
       "6      0         0             0           0            0      0    0       0   \n",
       "\n",
       "   ocupado  pasa  ...  podrías  pásala  recurso  renovable  sabiamente  \\\n",
       "0        0     0  ...        0       0        0          0           0   \n",
       "1        0     0  ...        0       0        0          0           0   \n",
       "2        0     0  ...        0       1        0          0           0   \n",
       "3        0     0  ...        0       0        0          0           0   \n",
       "4        1     1  ...        0       0        0          0           0   \n",
       "5        0     0  ...        0       0        1          1           1   \n",
       "6        0     0  ...        1       0        0          0           0   \n",
       "\n",
       "   tiempo  viaje  vida  éxito  úsalo  \n",
       "0       0      0     0      0      0  \n",
       "1       0      0     0      1      0  \n",
       "2       0      0     0      0      0  \n",
       "3       0      1     0      0      0  \n",
       "4       0      0     1      0      0  \n",
       "5       1      0     0      0      1  \n",
       "6       0      0     0      0      0  \n",
       "\n",
       "[7 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtenemos palabras únicas en el corpus\n",
    "vocab = cv.get_feature_names_out()\n",
    "# mostramos vectores de características BoW del corpus\n",
    "pd.DataFrame(cv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJI3OLRCCtC4"
   },
   "source": [
    "## Modelo N-grams\n",
    "EL modelo BoW N-grams Considera como términos del vocabulario cada secuencia de N palabras consecutivas que aparece en el Corpus.  \n",
    "Por ejemplo para los *bigrams* del corpus (N=2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vAbuyGBrAksg",
    "outputId": "935eb49d-4973-4432-c93c-ef4e6fc5256b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clave éxito' 'comienza paso' 'contagiosa pásala'\n",
      " 'creatividad contagiosa' 'estás ocupado' 'mil millas' 'millas comienza'\n",
      " 'ocupado planes' 'pasa estás' 'perseverancia clave' 'recurso renovable'\n",
      " 'renovable úsalo' 'tiempo recurso' 'viaje mil' 'vida pasa'\n",
      " 'úsalo sabiamente']\n"
     ]
    }
   ],
   "source": [
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(norm_corpus)\n",
    "\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab_bigram = bv.get_feature_names_out()\n",
    "print(vocab_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "tz5twpW_Cwph",
    "outputId": "acb80eee-9a0d-4620-fd55-0f1900720d39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clave éxito</th>\n",
       "      <th>comienza paso</th>\n",
       "      <th>contagiosa pásala</th>\n",
       "      <th>creatividad contagiosa</th>\n",
       "      <th>estás ocupado</th>\n",
       "      <th>mil millas</th>\n",
       "      <th>millas comienza</th>\n",
       "      <th>ocupado planes</th>\n",
       "      <th>pasa estás</th>\n",
       "      <th>perseverancia clave</th>\n",
       "      <th>recurso renovable</th>\n",
       "      <th>renovable úsalo</th>\n",
       "      <th>tiempo recurso</th>\n",
       "      <th>viaje mil</th>\n",
       "      <th>vida pasa</th>\n",
       "      <th>úsalo sabiamente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clave éxito  comienza paso  contagiosa pásala  creatividad contagiosa  \\\n",
       "0            0              0                  0                       0   \n",
       "1            1              0                  0                       0   \n",
       "2            0              0                  1                       1   \n",
       "3            0              1                  0                       0   \n",
       "4            0              0                  0                       0   \n",
       "5            0              0                  0                       0   \n",
       "6            0              0                  0                       0   \n",
       "\n",
       "   estás ocupado  mil millas  millas comienza  ocupado planes  pasa estás  \\\n",
       "0              0           0                0               0           0   \n",
       "1              0           0                0               0           0   \n",
       "2              0           0                0               0           0   \n",
       "3              0           1                1               0           0   \n",
       "4              1           0                0               1           1   \n",
       "5              0           0                0               0           0   \n",
       "6              0           0                0               0           0   \n",
       "\n",
       "   perseverancia clave  recurso renovable  renovable úsalo  tiempo recurso  \\\n",
       "0                    0                  0                0               0   \n",
       "1                    1                  0                0               0   \n",
       "2                    0                  0                0               0   \n",
       "3                    0                  0                0               0   \n",
       "4                    0                  0                0               0   \n",
       "5                    0                  1                1               1   \n",
       "6                    0                  0                0               0   \n",
       "\n",
       "   viaje mil  vida pasa  úsalo sabiamente  \n",
       "0          0          0                 0  \n",
       "1          0          0                 0  \n",
       "2          0          0                 0  \n",
       "3          1          0                 0  \n",
       "4          0          1                 0  \n",
       "5          0          0                 1  \n",
       "6          0          0                 0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bv_matrix, columns=vocab_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCQBwZ8dDCai"
   },
   "source": [
    "## Modelo TF-IDF\n",
    "Este modelo promedia la frecuencia de aparición de cada término (*Term Frequency*) por el número de documentos en los que aparece (*Inverse Document Frequency*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsT8oHqLC6Ko",
    "outputId": "bbd817db-df65-4ecd-f2eb-1cd2e43b2876"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se convierte el corpus en matriz\n",
    "tv = TfidfVectorizer(norm=None)\n",
    "tv_matrix = tv.fit_transform(norm_corpus)\n",
    "tv_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRiloI9KDPUZ"
   },
   "source": [
    "La matriz resultante tiene los mismos términos que la del modelo BoW, pero se aplica un peso diferente a cada término en función de su frecuencia de aparición en distintos documentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "1ZJuMpCsDGQu",
    "outputId": "5d5342d9-4184-4d54-bf24-c23064bf939b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clave</th>\n",
       "      <th>comienza</th>\n",
       "      <th>conocimiento</th>\n",
       "      <th>contagiosa</th>\n",
       "      <th>creatividad</th>\n",
       "      <th>estás</th>\n",
       "      <th>mil</th>\n",
       "      <th>millas</th>\n",
       "      <th>ocupado</th>\n",
       "      <th>pasa</th>\n",
       "      <th>...</th>\n",
       "      <th>podrías</th>\n",
       "      <th>pásala</th>\n",
       "      <th>recurso</th>\n",
       "      <th>renovable</th>\n",
       "      <th>sabiamente</th>\n",
       "      <th>tiempo</th>\n",
       "      <th>viaje</th>\n",
       "      <th>vida</th>\n",
       "      <th>éxito</th>\n",
       "      <th>úsalo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   clave  comienza  conocimiento  contagiosa  creatividad  estás   mil  \\\n",
       "0   0.00      0.00          2.39        0.00         0.00   0.00  0.00   \n",
       "1   2.39      0.00          0.00        0.00         0.00   0.00  0.00   \n",
       "2   0.00      0.00          0.00        2.39         2.39   0.00  0.00   \n",
       "3   0.00      2.39          0.00        0.00         0.00   0.00  2.39   \n",
       "4   0.00      0.00          0.00        0.00         0.00   2.39  0.00   \n",
       "5   0.00      0.00          0.00        0.00         0.00   0.00  0.00   \n",
       "6   0.00      0.00          0.00        0.00         0.00   0.00  0.00   \n",
       "\n",
       "   millas  ocupado  pasa  ...  podrías  pásala  recurso  renovable  \\\n",
       "0    0.00     0.00  0.00  ...     0.00    0.00     0.00       0.00   \n",
       "1    0.00     0.00  0.00  ...     0.00    0.00     0.00       0.00   \n",
       "2    0.00     0.00  0.00  ...     0.00    2.39     0.00       0.00   \n",
       "3    2.39     0.00  0.00  ...     0.00    0.00     0.00       0.00   \n",
       "4    0.00     2.39  2.39  ...     0.00    0.00     0.00       0.00   \n",
       "5    0.00     0.00  0.00  ...     0.00    0.00     2.39       2.39   \n",
       "6    0.00     0.00  0.00  ...     2.39    0.00     0.00       0.00   \n",
       "\n",
       "   sabiamente  tiempo  viaje  vida  éxito  úsalo  \n",
       "0        0.00    0.00   0.00  0.00   0.00   0.00  \n",
       "1        0.00    0.00   0.00  0.00   2.39   0.00  \n",
       "2        0.00    0.00   0.00  0.00   0.00   0.00  \n",
       "3        0.00    0.00   2.39  0.00   0.00   0.00  \n",
       "4        0.00    0.00   0.00  2.39   0.00   0.00  \n",
       "5        2.39    2.39   0.00  0.00   0.00   2.39  \n",
       "6        0.00    0.00   0.00  0.00   0.00   0.00  \n",
       "\n",
       "[7 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_matrix = tv_matrix.toarray()\n",
    "vocab = tv.get_feature_names_out()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Z-fh1Siybs-"
   },
   "source": [
    "## Word embeddings con spaCy\n",
    "Los word embeddings (o word vectors) son representaciones numéricas de las palabras, generadas con una reducción de dimensionalidad sobre una matriz de co-ocurrencia sobre un corpus enorme. Spacy utiliza los word vectors de GloVe, (*Stanford's Global Vectors for Word Representation*). Estos vectores se pueden utilizar para calcular la similaridad semántica entre palabras o documentos.\n",
    "\n",
    "El vocabulario por defecto en el modelo spaCy del idioma inglés (`en_core_web_sm`) es muy pequeño. Hay que cargar en_core_web_md (`python -m spacy download en_core_web_md`) para tener un conjunto de word vectors mayor. El modelo de tamaño medio en español (`python -m spacy download es_core_news_md`) contiene vectores también."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWTh0soRnF6t"
   },
   "source": [
    "#### Introducción a la librería spaCy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PH6UwTkqnbLt"
   },
   "source": [
    "##### Procesado de texto\n",
    "\n",
    "spaCy ejecuta todos los análisis del texto con una sola instrucción. Esta instrucción ejecuta un *pipeline* (procesado secuencial) que implementa:  \n",
    "\n",
    "- División en tokens  \n",
    "- Lematizado\n",
    "- Análisis gramatical\n",
    "- Análisis de dependencias\n",
    "- *Name Entity Recognition* (NER)\n",
    "\n",
    "Vamos a ver estas funcionalidades previamente a introducir el word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dW5CE0Bulne0"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de texto\n",
    "texto = \"El perro de San Roque es muy agresivo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxwyPSU3njZj",
    "outputId": "f41e5edd-86bf-40d6-a466-7b7fd574ff6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lo primero que hacemos es analizar el texto y generar un objeto de tipo `Doc`\n",
    "parsedData = nlp(texto)\n",
    "type(parsedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "VWGaYXM4noAP",
    "outputId": "53cf6d4a-3c5d-469d-ed5d-aafa2203bc89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lema</th>\n",
       "      <th>shape</th>\n",
       "      <th>POS</th>\n",
       "      <th>POS detallado</th>\n",
       "      <th>dependencia</th>\n",
       "      <th>Descripción dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El</td>\n",
       "      <td>el</td>\n",
       "      <td>Xx</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perro</td>\n",
       "      <td>perro</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>nominal subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>xx</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>case</td>\n",
       "      <td>case marking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San</td>\n",
       "      <td>San</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat</td>\n",
       "      <td>flat multiword expression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roque</td>\n",
       "      <td>Roque</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>flat</td>\n",
       "      <td>flat multiword expression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>es</td>\n",
       "      <td>ser</td>\n",
       "      <td>xx</td>\n",
       "      <td>AUX</td>\n",
       "      <td>AUX</td>\n",
       "      <td>cop</td>\n",
       "      <td>copula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>muy</td>\n",
       "      <td>mucho</td>\n",
       "      <td>xxx</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "      <td>adverbial modifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>agresivo</td>\n",
       "      <td>agresivo</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>punctuation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token      lema  shape    POS POS detallado dependencia  \\\n",
       "0        El        el     Xx    DET           DET         det   \n",
       "1     perro     perro   xxxx  PROPN         PROPN       nsubj   \n",
       "2        de        de     xx    ADP           ADP        case   \n",
       "3       San       San    Xxx  PROPN         PROPN        flat   \n",
       "4     Roque     Roque  Xxxxx  PROPN         PROPN        flat   \n",
       "5        es       ser     xx    AUX           AUX         cop   \n",
       "6       muy     mucho    xxx    ADV           ADV      advmod   \n",
       "7  agresivo  agresivo   xxxx    ADJ           ADJ        ROOT   \n",
       "8         .         .      .  PUNCT         PUNCT       punct   \n",
       "\n",
       "             Descripción dep  \n",
       "0                 determiner  \n",
       "1            nominal subject  \n",
       "2               case marking  \n",
       "3  flat multiword expression  \n",
       "4  flat multiword expression  \n",
       "5                     copula  \n",
       "6         adverbial modifier  \n",
       "7                       root  \n",
       "8                punctuation  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = map(lambda t: {'token': t.orth_,\n",
    "                       'lema': t.lemma_,\n",
    "                       'shape': t.shape_,\n",
    "                       'POS': t.pos_,\n",
    "                       'POS detallado': t.tag_,\n",
    "                       'dependencia': t.dep_,\n",
    "                       'Descripción dep': spacy.explain(t.dep_)}, parsedData)\n",
    "\n",
    "pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ1370tNnr-p"
   },
   "source": [
    "###### Exploramos el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMjNmXCtnxFR",
    "outputId": "6b6cdafb-9699-48e3-ef4c-24f91e308afe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[El, perro, de, San, Roque, es, muy, agresivo, .]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Al analizar un texto, spaCy lo divide en una lista de `tokens`, que se acceden iterando sobre el objeto `Doc`\n",
    "[t for t in parsedData]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2dFG9ANoUsi"
   },
   "source": [
    "Las propiedades más importantes son (https://spacy.io/api/token#attributes):  \n",
    "* `orth_`: texto del token\n",
    "* `lemma_`: lema (palabra base)\n",
    "* `shape_`: forma ortográfica del token\n",
    "* `pos_`: Part-of-Speech (genérico)\n",
    "* `tag_`: POS detallado\n",
    "* `dep_`: Tipo de dependencia del token (análisis de dependencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtpKrQiho6Rx"
   },
   "source": [
    "##### Análisis gramatical\n",
    "Los documentos SpaCy también dividen en texto en oraciones (*sentences*) que son objetos del tipo `spacy.tokens.span.Span`. Podemos iterar con el generador `doc.sents` usando `next()`, `list()`, un bucle o con una comprensión de lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wnX0o9qo7Kj",
    "outputId": "e2c89618-687a-4a53-e771-96cb95bf2a34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "La Inteligencia Artificial (IA) es una de las revoluciones tecnológicas más significativas de nuestro tiempo. Este campo multidisciplinario de la informática se enfoca en desarrollar sistemas y algoritmos que pueden realizar tareas que, en el pasado, requerían la intervención humana y el razonamiento. La IA busca imitar y automatizar el pensamiento humano, lo que abre un mundo de posibilidades en diversas industrias y aspectos de la vida cotidiana.\n",
       "\n",
       "Uno de los hitos más destacados de la IA es el aprendizaje automático (Machine Learning), que permite a las máquinas aprender y mejorar su rendimiento a partir de datos y experiencias previas. Esto ha llevado al desarrollo de sistemas capaces de tomar decisiones informadas, como los vehículos autónomos, que pueden conducir de manera segura y eficiente, o los sistemas de recomendación en plataformas de streaming, que sugieren contenido personalizado.\n",
       "\n",
       "En la medicina, la IA ha demostrado su valía en la detección temprana de enfermedades, la interpretación de imágenes médicas y la optimización de tratamientos. En la atención al cliente, los chatbots y asistentes virtuales proporcionan respuestas instantáneas y ayudan a resolver consultas.\n",
       "\n",
       "La IA también tiene un impacto importante en la industria manufacturera, donde la automatización y la robótica inteligente mejoran la eficiencia y la calidad de la producción. Además, en la investigación científica, la IA ayuda a analizar grandes conjuntos de datos y a realizar descubrimientos importantes.\n",
       "\n",
       "Sin embargo, la IA no está exenta de desafíos. Se plantean cuestiones éticas, como la privacidad de los datos y la toma de decisiones algorítmicas. También se debate sobre el posible impacto en el empleo, ya que algunas tareas humanas pueden ser automatizadas.\n",
       "\n",
       "En resumen, la Inteligencia Artificial es una fuerza impulsora que está transformando radicalmente la forma en que vivimos y trabajamos. A medida que continúa avanzando, es esencial abordar sus desafíos éticos y sociales, al tiempo que se aprovecha su potencial para mejorar la eficiencia, la precisión y la calidad de vida en todo el mundo. La IA está moldeando el futuro y promete seguir sorprendiéndonos con sus innovaciones y aplicaciones aún no descubiertas."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"\"\"\n",
    "La Inteligencia Artificial (IA) es una de las revoluciones tecnológicas más significativas de nuestro tiempo. Este campo multidisciplinario de la informática se enfoca en desarrollar sistemas y algoritmos que pueden realizar tareas que, en el pasado, requerían la intervención humana y el razonamiento. La IA busca imitar y automatizar el pensamiento humano, lo que abre un mundo de posibilidades en diversas industrias y aspectos de la vida cotidiana.\n",
    "\n",
    "Uno de los hitos más destacados de la IA es el aprendizaje automático (Machine Learning), que permite a las máquinas aprender y mejorar su rendimiento a partir de datos y experiencias previas. Esto ha llevado al desarrollo de sistemas capaces de tomar decisiones informadas, como los vehículos autónomos, que pueden conducir de manera segura y eficiente, o los sistemas de recomendación en plataformas de streaming, que sugieren contenido personalizado.\n",
    "\n",
    "En la medicina, la IA ha demostrado su valía en la detección temprana de enfermedades, la interpretación de imágenes médicas y la optimización de tratamientos. En la atención al cliente, los chatbots y asistentes virtuales proporcionan respuestas instantáneas y ayudan a resolver consultas.\n",
    "\n",
    "La IA también tiene un impacto importante en la industria manufacturera, donde la automatización y la robótica inteligente mejoran la eficiencia y la calidad de la producción. Además, en la investigación científica, la IA ayuda a analizar grandes conjuntos de datos y a realizar descubrimientos importantes.\n",
    "\n",
    "Sin embargo, la IA no está exenta de desafíos. Se plantean cuestiones éticas, como la privacidad de los datos y la toma de decisiones algorítmicas. También se debate sobre el posible impacto en el empleo, ya que algunas tareas humanas pueden ser automatizadas.\n",
    "\n",
    "En resumen, la Inteligencia Artificial es una fuerza impulsora que está transformando radicalmente la forma en que vivimos y trabajamos. A medida que continúa avanzando, es esencial abordar sus desafíos éticos y sociales, al tiempo que se aprovecha su potencial para mejorar la eficiencia, la precisión y la calidad de vida en todo el mundo. La IA está moldeando el futuro y promete seguir sorprendiéndonos con sus innovaciones y aplicaciones aún no descubiertas.\"\"\"\n",
    "parsedData = nlp(texto)\n",
    "parsedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlBQ3cQ_pBIz",
    "outputId": "3f6208b3-f772-4eb2-9359-3aac6c6d432d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración 0:\n",
      "\n",
      "\n",
      "\n",
      "Oración 1:\n",
      "La Inteligencia Artificial (IA) es una de las revoluciones tecnológicas más significativas de nuestro tiempo.\n",
      "\n",
      "Oración 2:\n",
      "Este campo multidisciplinario de la informática se enfoca en desarrollar sistemas y algoritmos que pueden realizar tareas que, en el pasado, requerían la intervención humana y el razonamiento.\n",
      "\n",
      "Oración 3:\n",
      "La IA busca imitar y automatizar el pensamiento humano, lo que abre un mundo de posibilidades en diversas industrias y aspectos de la vida cotidiana.\n",
      "\n",
      "\n",
      "\n",
      "Oración 4:\n",
      "Uno de los hitos más destacados de la IA es el aprendizaje automático (Machine Learning), que permite a las máquinas aprender y mejorar su rendimiento a partir de datos y experiencias previas.\n",
      "\n",
      "Oración 5:\n",
      "Esto ha llevado al desarrollo de sistemas capaces de tomar decisiones informadas, como los vehículos autónomos, que pueden conducir de manera segura y eficiente, o los sistemas de recomendación en plataformas de streaming, que sugieren contenido personalizado.\n",
      "\n",
      "\n",
      "\n",
      "Oración 6:\n",
      "En la medicina, la IA ha demostrado su valía en la detección temprana de enfermedades, la interpretación de imágenes médicas y la optimización de tratamientos.\n",
      "\n",
      "Oración 7:\n",
      "En la atención al cliente, los chatbots y asistentes virtuales proporcionan respuestas instantáneas y ayudan a resolver consultas.\n",
      "\n",
      "\n",
      "\n",
      "Oración 8:\n",
      "La IA también tiene un impacto importante en la industria manufacturera, donde la automatización y la robótica inteligente mejoran la eficiencia y la calidad de la producción.\n",
      "\n",
      "Oración 9:\n",
      "Además, en la investigación científica, la IA ayuda a analizar grandes conjuntos de datos y a realizar descubrimientos importantes.\n",
      "\n",
      "\n",
      "\n",
      "Oración 10:\n",
      "Sin embargo, la IA no está exenta de desafíos.\n",
      "\n",
      "Oración 11:\n",
      "Se plantean cuestiones éticas, como la privacidad de los datos y la toma de decisiones algorítmicas.\n",
      "\n",
      "Oración 12:\n",
      "También se debate sobre el posible impacto en el empleo, ya que algunas tareas humanas pueden ser automatizadas.\n",
      "\n",
      "\n",
      "\n",
      "Oración 13:\n",
      "En resumen, la Inteligencia Artificial es una fuerza impulsora que está transformando radicalmente la forma en que vivimos y trabajamos.\n",
      "\n",
      "Oración 14:\n",
      "A medida que continúa avanzando, es esencial abordar sus desafíos éticos y sociales, al tiempo que se aprovecha su potencial para mejorar la eficiencia, la precisión y la calidad de vida en todo el mundo.\n",
      "\n",
      "Oración 15:\n",
      "La IA está moldeando el futuro y promete seguir sorprendiéndonos con sus innovaciones y aplicaciones aún no descubiertas.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# oraciones\n",
    "for i, sent in enumerate(parsedData.sents):\n",
    "    print(\"Oración {}:\\n{}\\n\".format(i,sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqvUUhu4rkdk"
   },
   "source": [
    "###### Part of Speech (POS)\n",
    "La librería `spaCy` determina el tipo gramatical (POS) de cada palabra en nuestro texto. Creamos un diccionario con los distintos POS de nuestro texto de ejemplo, usando el *hash* de cada POS como clave del diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sy3bYO0vrf5Y",
    "outputId": "a6cccc85-23d7-42d3-edfd-751773f36205"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{103: ('SPACE', 'space'),\n",
       " 90: ('DET', 'determiner'),\n",
       " 96: ('PROPN', 'proper noun'),\n",
       " 97: ('PUNCT', 'punctuation'),\n",
       " 87: ('AUX', 'auxiliary'),\n",
       " 95: ('PRON', 'pronoun'),\n",
       " 85: ('ADP', 'adposition'),\n",
       " 92: ('NOUN', 'noun'),\n",
       " 84: ('ADJ', 'adjective'),\n",
       " 86: ('ADV', 'adverb'),\n",
       " 100: ('VERB', 'verb'),\n",
       " 89: ('CCONJ', 'coordinating conjunction'),\n",
       " 98: ('SCONJ', 'subordinating conjunction')}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{w.pos: (w.pos_, spacy.explain(w.pos_)) for w in parsedData}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSi5mq7ErudI"
   },
   "source": [
    "Cada tipo gramatical (POS) se subdivide en distintas etiquetas (POS detallado o tag).\n",
    "Por ejemplo en nuestro texto tenemos los siguientes tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5ws2ThgroOx",
    "outputId": "a4112ef8-5e04-4735-94c9-885bc8e37599"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('ADJ', 'ADJ'),\n",
       " ('ADP', 'ADP'),\n",
       " ('ADV', 'ADV'),\n",
       " ('AUX', 'AUX'),\n",
       " ('CCONJ', 'CCONJ'),\n",
       " ('DET', 'DET'),\n",
       " ('NOUN', 'NOUN'),\n",
       " ('PRON', 'PRON'),\n",
       " ('PROPN', 'PROPN'),\n",
       " ('PUNCT', 'PUNCT'),\n",
       " ('SCONJ', 'SCONJ'),\n",
       " ('SPACE', 'SPACE'),\n",
       " ('VERB', 'VERB')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([(w.pos_, w.tag_) for w in parsedData])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OP958DXIsoZC"
   },
   "source": [
    "###### Análisis de dependencias (dependency parsing)\n",
    "La librería `spaCy`también analiza las relaciones entre palabras de una frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "YfEGIMq4ss0h",
    "outputId": "28ffef2d-5300-4cc2-bbad-f85922c2c995"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>dependencia</th>\n",
       "      <th>explicación</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La</td>\n",
       "      <td>det</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alhambra</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>nominal subject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>case</td>\n",
       "      <td>case marking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Granada</td>\n",
       "      <td>flat</td>\n",
       "      <td>flat multiword expression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es</td>\n",
       "      <td>cop</td>\n",
       "      <td>copula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>un</td>\n",
       "      <td>det</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>monumento</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>muy</td>\n",
       "      <td>advmod</td>\n",
       "      <td>adverbial modifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bonito</td>\n",
       "      <td>amod</td>\n",
       "      <td>adjectival modifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>punctuation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       texto dependencia                explicación\n",
       "0         La         det                 determiner\n",
       "1   Alhambra       nsubj            nominal subject\n",
       "2         de        case               case marking\n",
       "3    Granada        flat  flat multiword expression\n",
       "4         es         cop                     copula\n",
       "5         un         det                 determiner\n",
       "6  monumento        ROOT                       root\n",
       "7        muy      advmod         adverbial modifier\n",
       "8     bonito        amod        adjectival modifier\n",
       "9          .       punct                punctuation"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto2 = \"La Alhambra de Granada es un monumento muy bonito.\"\n",
    "\n",
    "parsedData2 = nlp(texto2)\n",
    "dependencias = [(t.text, t.dep_, spacy.explain(t.dep_)) for t in parsedData2]\n",
    "pd.DataFrame(list(dependencias), columns=['texto', 'dependencia', 'explicación'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jO6NhkRwsxFF",
    "outputId": "40759648-e910-480e-8683-96f70ea74a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La :  []\n",
      "Alhambra :  [La, Granada]\n",
      "de :  []\n",
      "Granada :  [de]\n",
      "es :  []\n",
      "un :  []\n",
      "monumento :  [Alhambra, es, un, bonito, .]\n",
      "muy :  []\n",
      "bonito :  [muy]\n",
      ". :  []\n"
     ]
    }
   ],
   "source": [
    "# Análisis a cada palabra del texto.\n",
    "sent=next(parsedData2.sents)\n",
    "for word in sent:\n",
    "    print(word, ': ', str(list(word.children)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos las dependencias de cada palabra para una sentencia. Cada palabra tiene una palabra de la que depende (.head) y unas palabras que dependen de ella (children) a izquierda (.lefts) y a derecha (.rights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabra: [tipo de dependencia] HEAD\n",
      "-----------------------------------\n",
      "La: [det(determiner)] |HEAD:Alhambra\n",
      "Alhambra: [nsubj(nominal subject)] |HEAD:monumento\n",
      "de: [case(case marking)] |HEAD:Granada\n",
      "Granada: [flat(flat multiword expression)] |HEAD:Alhambra\n",
      "es: [cop(copula)] |HEAD:monumento\n",
      "un: [det(determiner)] |HEAD:monumento\n",
      "monumento: [ROOT(root)] |HEAD:monumento\n",
      "muy: [advmod(adverbial modifier)] |HEAD:bonito\n",
      "bonito: [amod(adjectival modifier)] |HEAD:monumento\n",
      ".: [punct(punctuation)] |HEAD:monumento\n",
      "\n",
      "[Dependencias izquierdas]<---palabra[tipo de dependencia]--->[dependencias derechas]\n",
      "[]<---La[det]--->[]\n",
      "-----\n",
      "['La']<---Alhambra[nsubj]--->['Granada']\n",
      "-----\n",
      "[]<---de[case]--->[]\n",
      "-----\n",
      "['de']<---Granada[flat]--->[]\n",
      "-----\n",
      "[]<---es[cop]--->[]\n",
      "-----\n",
      "[]<---un[det]--->[]\n",
      "-----\n",
      "['Alhambra', 'es', 'un']<---monumento[ROOT]--->['bonito', '.']\n",
      "-----\n",
      "[]<---muy[advmod]--->[]\n",
      "-----\n",
      "['muy']<---bonito[amod]--->[]\n",
      "-----\n",
      "[]<---.[punct]--->[]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "print(\"Palabra: [tipo de dependencia] HEAD\")\n",
    "print(\"-----------------------------------\")\n",
    "for token in parsedData2:\n",
    "    print(\"{}: [{}({})] |HEAD:{}\".format(token.orth_, token.dep_, spacy.explain(token.dep_), token.head.orth_))\n",
    "\n",
    "print(\"\\n[Dependencias izquierdas]<---palabra[tipo de dependencia]--->[dependencias derechas]\")\n",
    "for token in parsedData2:\n",
    "    print(\"{left}<---{word}[{dep_tag}]--->{right}\\n-----\".format(word=token.orth_,\n",
    "        dep_tag=token.dep_, left=[t.orth_ for t in token.lefts],\n",
    "        right=[t.orth_ for t in token.rights]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "0rZ_2CaLtFMG",
    "outputId": "1309d232-a819-47a8-d8bd-c815641082ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"es\" id=\"ddd1333cbdc346abbe4da35e0c343da9-0\" class=\"displacy\" width=\"1130\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">La</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">Alhambra</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Granada</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">es</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">un</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">monumento</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">muy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">bonito.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd1333cbdc346abbe4da35e0c343da9-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,122.0 160.0,122.0 160.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd1333cbdc346abbe4da35e0c343da9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd1333cbdc346abbe4da35e0c343da9-0-1\" stroke-width=\"2px\" d=\"M190,182.0 C190,2.0 770.0,2.0 770.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd1333cbdc346abbe4da35e0c343da9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,184.0 L182,172.0 198,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd1333cbdc346abbe4da35e0c343da9-0-2\" stroke-width=\"2px\" d=\"M310,182.0 C310,122.0 400.0,122.0 400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd1333cbdc346abbe4da35e0c343da9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310,184.0 L302,172.0 318,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd1333cbdc346abbe4da35e0c343da9-0-3\" stroke-width=\"2px\" d=\"M190,182.0 C190,62.0 405.0,62.0 405.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd1333cbdc346abbe4da35e0c343da9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">flat</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M405.0,184.0 L413.0,172.0 397.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd1333cbdc346abbe4da35e0c343da9-0-4\" stroke-width=\"2px\" d=\"M550,182.0 C550,62.0 765.0,62.0 765.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd1333cbdc346abbe4da35e0c343da9-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550,184.0 L542,172.0 558,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd1333cbdc346abbe4da35e0c343da9-0-5\" stroke-width=\"2px\" d=\"M670,182.0 C670,122.0 760.0,122.0 760.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd1333cbdc346abbe4da35e0c343da9-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,184.0 L662,172.0 678,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd1333cbdc346abbe4da35e0c343da9-0-6\" stroke-width=\"2px\" d=\"M910,182.0 C910,122.0 1000.0,122.0 1000.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd1333cbdc346abbe4da35e0c343da9-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910,184.0 L902,172.0 918,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ddd1333cbdc346abbe4da35e0c343da9-0-7\" stroke-width=\"2px\" d=\"M790,182.0 C790,62.0 1005.0,62.0 1005.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ddd1333cbdc346abbe4da35e0c343da9-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1005.0,184.0 L1013.0,172.0 997.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(parsedData2, style='dep', jupyter=True, options={'distance':120})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Búsqueda de patrones\n",
    "Spacy tiene una clase Matcher que permite buscar tokens con un patrón definido en los objetos Doc. Se puede buscar por el texto del token o por atributos del token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "#inicializamos sobre el vocabulario\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add() takes exactly 2 positional arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13572\\2330041511.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#definimos un patrón de texto a buscar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpatron\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"TEXT\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"iPhone\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"TEXT\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"X\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Patrón: texto 'iPhone' seguido de texto 'X'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"iphone_x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatron\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#procesamos un documento con el patrón\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\matcher\\matcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.matcher.Matcher.add\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: add() takes exactly 2 positional arguments (3 given)"
     ]
    }
   ],
   "source": [
    "#definimos un patrón de texto a buscar\n",
    "patron = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}] #Patrón: texto 'iPhone' seguido de texto 'X'\n",
    "matcher.add(\"iphone_x\", None, patron)\n",
    "\n",
    "#procesamos un documento con el patrón\n",
    "doc = nlp(\"El iPhone X salió después del iPhone 8, pero nunca sacaron el iPhone 9\")\n",
    "\n",
    "#llamamos al matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "#iteramos sobre los resultados\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Análisis de dependencias (dependency parsing)\n",
    "La librería `spaCy`también analiza las relaciones entre palabras de una frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tNxGIeJtaZT",
    "outputId": "d0c63e2f-de53-42bf-d884-24856620c285"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revoluciones tecnológicas\n",
      "campo multidisciplinario\n",
      "intervención humana\n",
      "pensamiento humano\n",
      "vida cotidiana\n",
      "aprendizaje automático\n",
      "experiencias previas\n",
      "sistemas capaces\n",
      "decisiones informadas\n",
      "vehículos autónomos\n",
      "manera segura\n",
      "contenido personalizado\n",
      "detección temprana\n",
      "imágenes médicas\n",
      "asistentes virtuales\n",
      "respuestas instantáneas\n",
      "impacto importante\n",
      "industria manufacturera\n",
      "robótica inteligente\n",
      "investigación científica\n",
      "descubrimientos importantes\n",
      "cuestiones éticas\n",
      "decisiones algorítmicas\n",
      "tareas humanas\n",
      "fuerza impulsora\n",
      "desafíos éticos\n"
     ]
    }
   ],
   "source": [
    "#inicializamos matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "#definimos un patrón\n",
    "patron = [{\"POS\": \"NOUN\"}, {\"POS\": \"ADJ\"}]\n",
    "matcher.add(\"nombre+adjetivo\", [patron])\n",
    "\n",
    "#procesamos un texto con el patron\n",
    "doc = nlp(texto)\n",
    "#llamamos al matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "#iteramos sobre el resultado\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDX6v-4exV0a"
   },
   "source": [
    "##### Explorando las entidades propias (Named Entities)\n",
    "La librería `spaCy` determina las entidades propias que aparecen en el texto. Podemos acceder a las entidades de un documento a través de su atributo `doc.ents`.  \n",
    "Por ejemplo en el artículo cargado hay las siguientes entidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "wT0jmgoJ1tqM"
   },
   "outputs": [],
   "source": [
    "texto_raw = \"\"\"La relación entre Madrid y Barcelona es una de las más intrigantes y complejas en España, y de hecho, en toda Europa. Estas dos ciudades icónicas tienen historias y personalidades distintas, pero también comparten muchos aspectos en común.\n",
    "Madrid, como la capital de España, desempeña un papel central en la vida política, económica y cultural del país. Es conocida por su vitalidad, su bullicioso ambiente y su rica historia. Barcelona, por otro lado, es la capital de Cataluña y tiene su propia identidad única. Es famosa por su arquitectura modernista, sus playas mediterráneas y su cultura cosmopolita.\n",
    "A lo largo de la historia, Madrid y Barcelona han competido en diversos aspectos, desde el deporte hasta la economía y la influencia política. Una de las rivalidades más intensas se encuentra en el fútbol, donde el clásico enfrentamiento entre el Real Madrid y el FC Barcelona es seguido con pasión en todo el mundo. Esta rivalidad refleja en parte las tensiones históricas entre las regiones de Castilla (donde se encuentra Madrid) y Cataluña.\n",
    "No obstante, en los últimos años, la relación entre Madrid y Barcelona ha evolucionado. Ambas ciudades son motores económicos de España y, en muchos aspectos, se complementan mutuamente. Madrid es el centro financiero y político, mientras que Barcelona es líder en la industria creativa, el turismo y la innovación. Muchas empresas tienen presencia en ambas ciudades, lo que ha contribuido a una mayor interconexión.\n",
    "En términos de cultura, Madrid y Barcelona son centros culturales vibrantes y atractivos para artistas, músicos y amantes de las artes en general. Ambas ciudades albergan museos e renombre mundial, teatros y eventos culturales que enriquecen la vida de sus habitantes y visitantes.\n",
    "A nivel turístico, Madrid y Barcelona son dos de los destinos más populares de España. Los viajeros pueden disfrutar de la belleza arquitectónica de Barcelona, con obras maestras como la Sagrada Familia de Gaudí, y luego sumergirse en la historia y la gastronomía de Madrid, con su impresionante Palacio Real y sus famosos mercados de alimentos.\n",
    "En resumen, la relación entre Madrid y Barcelona es una mezcla de competencia histórica y cooperación contemporánea. Estas dos ciudades emblemáticas de España, con sus diferencias y similitudes, siguen desempeñando un papel fundamental en la identidad y la cultura del país, contribuyendo a su diversidad y riqueza. La relación entre ellas es un reflejo de la complejidad y la dinámica de España como nación.\n",
    "\"\"\"\n",
    "doc = nlp(texto_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "XnxQVbpdxkax",
    "outputId": "5db4a59d-7ea0-468b-b006-6687e1d12534"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entidad</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barcelona</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>España</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europa</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cataluña</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Una de las rivalidades más intensas</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FC Barcelona</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Castilla</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Los viajeros pueden disfrutar de la belleza arquitectónica de Barcelona</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>la Sagrada Familia</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gaudí</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Palacio Real</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>La relación entre ellas</td>\n",
       "      <td>MISC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    entidad  \\\n",
       "0                                                                    Madrid   \n",
       "1                                                                 Barcelona   \n",
       "2                                                                    España   \n",
       "3                                                                    Europa   \n",
       "7                                                                  Cataluña   \n",
       "10                                      Una de las rivalidades más intensas   \n",
       "11                                                              Real Madrid   \n",
       "12                                                             FC Barcelona   \n",
       "13                                                                 Castilla   \n",
       "26  Los viajeros pueden disfrutar de la belleza arquitectónica de Barcelona   \n",
       "27                                                       la Sagrada Familia   \n",
       "28                                                                    Gaudí   \n",
       "30                                                             Palacio Real   \n",
       "34                                                  La relación entre ellas   \n",
       "\n",
       "    tipo  \n",
       "0    LOC  \n",
       "1    LOC  \n",
       "2    LOC  \n",
       "3    LOC  \n",
       "7    LOC  \n",
       "10  MISC  \n",
       "11   ORG  \n",
       "12   ORG  \n",
       "13   LOC  \n",
       "26  MISC  \n",
       "27   LOC  \n",
       "28   PER  \n",
       "30   LOC  \n",
       "34  MISC  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El atributo `doc.ents` devuelve una tupla con las entidades del documento (objetos de tipo `Span`)\n",
    "entities = [(e.text, e.label_) for e in doc.ents]\n",
    "pd.DataFrame(list(entities), columns=['entidad', 'tipo']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUCimcLqxyDy",
    "outputId": "718a96fe-1165-44a0-e8fd-ef266bfe4f0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': 'Non-GPE locations, mountain ranges, bodies of water',\n",
       " 'MISC': 'Miscellaneous entities, e.g. events, nationalities, products or works of art',\n",
       " 'ORG': 'Companies, agencies, institutions, etc.',\n",
       " 'PER': 'Named person or family.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Los tipos de entidades que aparecen en el documento son:\n",
    "{w.label_:spacy.explain(w.label_) for w in doc.ents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 962
    },
    "id": "oCtO8RgYyOH4",
    "outputId": "d8f37f26-8981-4414-ed08-9802b272923e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">La relación entre \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " es una de las más intrigantes y complejas en \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    España\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", y de hecho, en toda \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Europa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Estas dos ciudades icónicas tienen historias y personalidades distintas, pero también comparten muchos aspectos en común.<br>\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", como la capital de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    España\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", desempeña un papel central en la vida política, económica y cultural del país. Es conocida por su vitalidad, su bullicioso ambiente y su rica historia. \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", por otro lado, es la capital de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cataluña\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " y tiene su propia identidad única. Es famosa por su arquitectura modernista, sus playas mediterráneas y su cultura cosmopolita.<br>A lo largo de la historia, \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " han competido en diversos aspectos, desde el deporte hasta la economía y la influencia política. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Una de las rivalidades más intensas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " se encuentra en el fútbol, donde el clásico enfrentamiento entre el \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Real Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " y el \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    FC Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " es seguido con pasión en todo el mundo. Esta rivalidad refleja en parte las tensiones históricas entre las regiones de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Castilla\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " (donde se encuentra \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ") y \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cataluña\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".<br>No obstante, en los últimos años, la relación entre \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " ha evolucionado. Ambas ciudades son motores económicos de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    España\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " y, en muchos aspectos, se complementan mutuamente. \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " es el centro financiero y político, mientras que \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " es líder en la industria creativa, el turismo y la innovación. Muchas empresas tienen presencia en ambas ciudades, lo que ha contribuido a una mayor interconexión.<br>En términos de cultura, \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " son centros culturales vibrantes y atractivos para artistas, músicos y amantes de las artes en general. Ambas ciudades albergan museos e renombre mundial, teatros y eventos culturales que enriquecen la vida de sus habitantes y visitantes.<br>A nivel turístico, \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " son dos de los destinos más populares de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    España\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Los viajeros pueden disfrutar de la belleza arquitectónica de Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       ", con obras maestras como \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la Sagrada Familia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gaudí\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", y luego sumergirse en la historia y la gastronomía de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", con su impresionante \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Palacio Real\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " y sus famosos mercados de alimentos.<br>En resumen, la relación entre \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Madrid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Barcelona\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " es una mezcla de competencia histórica y cooperación contemporánea. Estas dos ciudades emblemáticas de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    España\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", con sus diferencias y similitudes, siguen desempeñando un papel fundamental en la identidad y la cultura del país, contribuyendo a su diversidad y riqueza. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    La relación entre ellas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " es un reflejo de la complejidad y la dinámica de \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    España\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " como nación.<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Podemos visualizar gráficamente las entidades en su contexto con displaCy:\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNp6p1r-U8U1"
   },
   "source": [
    "#### Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yU-Ggf10yTu-",
    "outputId": "11ead8ab-0108-4536-d36d-b3acbe2bfada"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.9316e-01, -1.9055e+00,  1.1441e+00, -4.5437e-01, -7.4829e-01,\n",
       "        3.8813e-01, -2.3510e+00, -1.6627e+00,  1.7095e+00, -1.8088e-01,\n",
       "        1.2363e+00, -9.0759e-02,  5.6769e-01,  2.2311e+00, -1.0389e+00,\n",
       "       -2.6093e+00, -3.0297e-01,  1.3868e+00, -2.5877e+00, -1.0528e+00,\n",
       "       -2.5049e+00,  7.1522e-01, -2.0612e+00,  9.4640e-01,  8.0187e-01,\n",
       "       -5.3548e-01, -2.5208e-01, -2.8305e-01,  2.3178e-01, -5.9537e-01,\n",
       "       -5.0337e-01, -9.7432e-01,  8.2222e-01, -2.3384e+00,  2.1131e+00,\n",
       "       -1.4344e+00,  2.0885e+00, -1.3344e+00,  4.8458e-01,  9.5693e-01,\n",
       "       -1.0339e+00,  2.1483e+00, -3.3474e+00,  1.1917e+00,  6.2875e-01,\n",
       "        1.1625e+00,  3.7431e-01, -2.3933e+00, -1.2356e-01,  8.3158e-01,\n",
       "       -2.6937e+00, -1.7771e+00,  3.8745e-01,  1.9141e+00, -1.9752e-01,\n",
       "       -2.0079e+00, -1.0141e+00,  6.3490e-02, -5.8045e-01,  1.9114e+00,\n",
       "        2.2471e+00,  3.0757e+00,  3.3882e-01, -2.6576e-01,  1.4031e+00,\n",
       "        1.5642e+00, -2.2871e+00,  1.6472e+00,  8.1172e-02, -1.5295e+00,\n",
       "        2.4696e-01, -3.7425e-01,  2.4163e+00,  1.3078e+00, -3.1548e-01,\n",
       "       -1.4180e+00,  2.4668e-01,  2.2903e+00, -1.4076e+00, -3.5063e-01,\n",
       "       -1.9054e+00, -2.0622e+00, -2.3405e+00,  3.2304e+00,  1.0355e+00,\n",
       "        1.8781e+00, -4.4343e-01, -1.0582e+00,  7.2270e-01,  7.6863e-01,\n",
       "       -2.2260e+00, -3.6477e-01, -1.5067e+00, -1.8401e-01, -8.7580e-01,\n",
       "        1.9083e-01,  4.6796e+00, -7.1419e-01, -5.8286e-01,  3.5436e+00,\n",
       "        8.4601e-01,  1.9854e+00,  4.8551e-01, -7.0832e-01, -2.2778e+00,\n",
       "       -2.5192e+00, -1.4245e+00,  2.6038e-01,  4.6673e-01,  5.5941e-01,\n",
       "        8.9696e-01,  2.3950e+00, -3.4564e-01, -7.7336e-01,  1.9419e-01,\n",
       "       -1.7636e+00, -2.2763e-01, -2.9078e-01,  2.8427e-01, -2.5543e+00,\n",
       "        2.0058e+00,  1.0609e-01, -1.8367e+00, -3.4026e+00, -3.9320e-02,\n",
       "        2.3840e-03, -1.1155e+00, -5.0264e-01,  7.1316e-01, -2.6366e+00,\n",
       "        4.3112e-01, -2.2656e+00, -2.5718e+00, -6.2706e-01,  2.5643e+00,\n",
       "        1.4459e+00,  2.1081e-01,  5.5711e-01,  2.1873e+00,  2.2289e-01,\n",
       "        2.0469e+00,  5.5973e-01,  1.6245e+00, -6.9591e-01,  1.6135e+00,\n",
       "       -3.3957e+00, -1.4611e+00, -3.8957e-01, -4.1610e-01, -1.4218e+00,\n",
       "        1.5598e-01,  1.2649e+00, -1.7963e+00,  2.1883e+00, -3.6296e+00,\n",
       "       -3.2812e-01, -1.0075e+00,  6.7439e-01,  4.1187e-01,  2.3850e+00,\n",
       "       -1.8624e+00,  2.6676e+00, -1.2527e+00, -1.2731e+00, -1.8459e+00,\n",
       "       -8.8553e-01, -2.1340e+00,  3.5566e+00, -1.8463e+00, -2.1183e+00,\n",
       "       -6.1023e-01, -1.5871e+00, -2.0428e-01,  1.6482e+00,  2.5467e-01,\n",
       "        1.9001e+00, -4.0477e-01, -2.2221e+00,  8.8004e-01, -1.3948e+00,\n",
       "        3.1485e-01,  1.1698e+00,  1.6700e+00,  8.6409e-01,  6.8206e-01,\n",
       "        1.2327e+00, -2.1190e-02,  3.0496e+00,  9.9391e-02, -6.0889e-01,\n",
       "        9.0772e-01,  6.5988e-01,  4.9454e-01, -8.7903e-01,  2.5151e-01,\n",
       "        1.9490e+00, -2.0897e+00, -2.6887e+00, -2.9849e+00, -1.3715e+00,\n",
       "       -1.0159e+00,  1.7870e+00, -4.1170e-02,  1.0119e+00,  1.4715e-01,\n",
       "       -4.4990e+00, -2.6379e-01, -2.7971e+00,  3.1465e+00, -1.6876e+00,\n",
       "        5.4732e-01,  2.5992e+00,  4.0646e-01,  5.2698e-01,  2.1658e+00,\n",
       "        4.0628e-01, -5.8271e-01, -5.5076e-01, -1.4369e-01, -4.1179e-02,\n",
       "        1.6240e+00,  4.0512e-01,  1.9116e-01, -1.8433e+00, -6.7458e-01,\n",
       "       -2.3255e-01, -9.2813e-01,  2.1091e-01,  9.6799e-01, -1.0807e+00,\n",
       "       -1.1876e+00, -8.1971e-02, -6.3423e-01, -1.3686e+00,  4.3958e-01,\n",
       "        4.9387e-01, -1.7115e+00,  9.8391e-02, -9.5018e-01,  4.8237e-01,\n",
       "       -1.4978e+00, -7.7257e-01, -1.0973e+00,  8.8508e-01, -1.4104e+00,\n",
       "       -2.4312e-01,  6.1382e-01, -7.7570e-01, -1.8171e-01,  1.3865e+00,\n",
       "        1.3908e+00, -2.9798e+00,  2.4206e-02, -1.0384e-01, -6.0564e-01,\n",
       "        1.5608e+00, -1.0296e+00, -2.1525e+00,  1.8142e+00, -1.2714e-01,\n",
       "       -5.4362e-02, -7.7985e-01,  2.0274e+00,  1.0691e+00,  6.5482e-01,\n",
       "       -1.4619e+00,  2.4353e-01,  2.9008e-01,  1.0839e+00, -1.4560e+00,\n",
       "       -1.5961e+00,  2.5501e+00, -2.1996e+00, -7.4136e-01, -2.3742e+00,\n",
       "       -1.9804e+00, -2.5721e+00,  9.0296e-01, -1.0416e+00, -1.8784e+00,\n",
       "       -1.1047e+00, -7.2156e-01, -1.8001e+00, -2.0351e+00,  1.0638e+00,\n",
       "        5.5024e-01,  4.4257e-01,  1.2055e+00, -2.1446e+00,  1.4196e-01,\n",
       "        7.6665e-02, -1.7614e+00,  7.2543e-01, -1.9125e+00,  2.9831e+00,\n",
       "       -2.0168e+00,  2.7614e+00,  6.6471e-01,  3.2699e+00,  8.9653e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generamos varios vectores\n",
    "madrid = nlp.vocab[\"Madrid\"]\n",
    "barcelona = nlp.vocab[\"Barcelona\"]\n",
    "granada = nlp.vocab[\"Granada\"]\n",
    "madrid.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtHOcuonzeAG",
    "outputId": "6ca95cc0-dba4-444f-9823-27bc2362f1b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8017494082450867\n",
      "0.6647977828979492\n",
      "0.6088482141494751\n"
     ]
    }
   ],
   "source": [
    "# similitudes entre vectores\n",
    "print(madrid.similarity(barcelona))\n",
    "print(madrid.similarity(granada))\n",
    "print(barcelona.similarity(granada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlxOqYGFzLyv",
    "outputId": "22972eeb-9267-42ee-f57d-985b0bde704d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitud: 451\n",
      "Top 20 palabras más similares a turismo:\n",
      "turístico\n",
      "gastronomía\n",
      "deporte\n",
      "cultural\n",
      "economía\n",
      "desarrollo\n",
      "cultura\n",
      "innovación\n",
      "económica\n",
      "culturales\n",
      "industria\n",
      "destinos\n",
      "empleo\n",
      "ambiente\n",
      "diversidad\n",
      "potencial\n",
      "industrias\n",
      "capital\n",
      "atractivos\n",
      "viajeros\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos las n palabras más cercanas a: turismo\n",
    "turismo = nlp.vocab['turismo']\n",
    "\n",
    "# cogemos todas las palabras del vocabulario que tienen vector, en minúsculas\n",
    "allWords = list({w for w in nlp.vocab if w.has_vector and w.orth_.islower() and w.lower_ != \"turismo\"})\n",
    "\n",
    "print(\"longitud:\",len(allWords))\n",
    "\n",
    "# ordenamos por similitud con turismo\n",
    "allWords.sort(key=lambda w: turismo.similarity(w))\n",
    "allWords.reverse()\n",
    "print(\"Top 20 palabras más similares a turismo:\")\n",
    "for word in allWords[:20]:\n",
    "    print(word.orth_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
